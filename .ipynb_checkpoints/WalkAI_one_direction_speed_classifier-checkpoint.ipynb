{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2",
   "metadata": {
    "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from numpy.random import default_rng\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NKCFZxY--SlA",
   "metadata": {
    "id": "NKCFZxY--SlA"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/walk_data_14_Fernando.txt', sep=\",\", header=None, names=[\"e_t_x\",\"e_t_y\",\"e_t_z\",\"e_r_x\",\"e_r_y\",\"e_r_z\",\"e_r_w\",\"d_t_x\",\"d_t_y\",\"d_t_z\",\"d_r_x\",\"d_r_y\",\"d_r_z\",\"d_r_w\", \"c_t_x\",\"c_t_y\",\"c_t_z\",\"c_r_x\",\"c_r_y\",\"c_r_z\", \"c_r_w\"])\n",
    "# data_fernando = pd.read_csv('data/walk_data_1_Fernando.txt', sep=\",\", header=None, names=[\"e_t_x\",\"e_t_y\",\"e_t_z\",\"e_r_x\",\"e_r_y\",\"e_r_z\",\"d_t_x\",\"d_t_y\",\"d_t_z\",\"d_r_x\",\"d_r_y\",\"d_r_z\",\"c_t_x\",\"c_t_y\",\"c_t_z\",\"c_r_x\",\"c_r_y\",\"c_r_z\"])\n",
    "data = pd.read_csv('data/full_data.txt', sep=\",\", header=None, names=[\"e_t_x\",\"e_t_y\",\"e_t_z\",\"e_r_x\",\"e_r_y\",\"e_r_z\",\"e_r_w\",\"d_t_x\",\"d_t_y\",\"d_t_z\",\"d_r_x\",\"d_r_y\",\"d_r_z\",\"d_r_w\", \"c_t_x\",\"c_t_y\",\"c_t_z\",\"c_r_x\",\"c_r_y\",\"c_r_z\", \"c_r_w\", \"speed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CEcxIBOK_lHV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "CEcxIBOK_lHV",
    "outputId": "1e0ab457-f819-4840-c77e-779ac3ef75ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_t_x</th>\n",
       "      <th>e_t_y</th>\n",
       "      <th>e_t_z</th>\n",
       "      <th>e_r_x</th>\n",
       "      <th>e_r_y</th>\n",
       "      <th>e_r_z</th>\n",
       "      <th>e_r_w</th>\n",
       "      <th>d_t_x</th>\n",
       "      <th>d_t_y</th>\n",
       "      <th>d_t_z</th>\n",
       "      <th>...</th>\n",
       "      <th>d_r_z</th>\n",
       "      <th>d_r_w</th>\n",
       "      <th>c_t_x</th>\n",
       "      <th>c_t_y</th>\n",
       "      <th>c_t_z</th>\n",
       "      <th>c_r_x</th>\n",
       "      <th>c_r_y</th>\n",
       "      <th>c_r_z</th>\n",
       "      <th>c_r_w</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419990</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419991</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419992</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419993</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419994</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419995 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        e_t_x  e_t_y  e_t_z  e_r_x  e_r_y  e_r_z  e_r_w  d_t_x  d_t_y  d_t_z  \\\n",
       "0       0.000  0.000  0.000 -0.002  0.006 -0.006 -0.005  0.000  0.000  0.000   \n",
       "1       0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2       0.000  0.000  0.001  0.002  0.001 -0.001  0.002  0.000  0.001  0.000   \n",
       "3       0.000 -0.001  0.000  0.001  0.001 -0.001  0.002  0.000  0.000  0.000   \n",
       "4       0.000  0.000  0.000  0.000  0.001 -0.001  0.000  0.000  0.000  0.001   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "419990  0.000  0.000  0.000  0.000  0.003 -0.003 -0.001  0.007  0.004  0.037   \n",
       "419991  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419992  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419993  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419994  0.001  0.000  0.001  0.000 -0.001  0.000  0.000  0.005  0.000  0.044   \n",
       "\n",
       "        ...  d_r_z  d_r_w  c_t_x  c_t_y  c_t_z  c_r_x  c_r_y  c_r_z  c_r_w  \\\n",
       "0       ...  0.000 -0.001 -0.004  0.001  0.001  0.000 -0.001  0.003  0.000   \n",
       "1       ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "2       ...  0.001 -0.001 -0.003  0.001  0.000  0.000 -0.002  0.004  0.001   \n",
       "3       ...  0.000  0.001 -0.004  0.000  0.000 -0.001 -0.002  0.003  0.000   \n",
       "4       ...  0.000  0.000 -0.004  0.001  0.000  0.000 -0.002  0.004  0.001   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "419990  ...  0.012 -0.022  0.002  0.001  0.001 -0.004 -0.002  0.005  0.001   \n",
       "419991  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419992  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419993  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "419994  ...  1.536  0.004  0.003  0.000  0.002 -0.001 -0.001  0.003  0.000   \n",
       "\n",
       "          speed  \n",
       "0       stopped  \n",
       "1       stopped  \n",
       "2       stopped  \n",
       "3       stopped  \n",
       "4       stopped  \n",
       "...         ...  \n",
       "419990     fast  \n",
       "419991     fast  \n",
       "419992     fast  \n",
       "419993     fast  \n",
       "419994     fast  \n",
       "\n",
       "[419995 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TiXnPjZND-oG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "TiXnPjZND-oG",
    "outputId": "0d53f1a2-cc23-4e44-a849-7b35233d8ee7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-21d99e37-d4ab-406f-a27f-999add618e9e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_t_x</th>\n",
       "      <th>e_t_y</th>\n",
       "      <th>e_t_z</th>\n",
       "      <th>e_r_x</th>\n",
       "      <th>e_r_y</th>\n",
       "      <th>e_r_z</th>\n",
       "      <th>e_r_w</th>\n",
       "      <th>d_t_x</th>\n",
       "      <th>d_t_y</th>\n",
       "      <th>d_t_z</th>\n",
       "      <th>...</th>\n",
       "      <th>c_r_x</th>\n",
       "      <th>c_r_y</th>\n",
       "      <th>c_r_z</th>\n",
       "      <th>c_r_w</th>\n",
       "      <th>name</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>speed(kg)</th>\n",
       "      <th>direction</th>\n",
       "      <th>angle</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>one_direction</td>\n",
       "      <td>0</td>\n",
       "      <td>stopped</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 27 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21d99e37-d4ab-406f-a27f-999add618e9e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-21d99e37-d4ab-406f-a27f-999add618e9e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-21d99e37-d4ab-406f-a27f-999add618e9e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     e_t_x  e_t_y  e_t_z  e_r_x  e_r_y  e_r_z  e_r_w  d_t_x  d_t_y  d_t_z  \\\n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "895    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "896    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "897    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "898    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "899    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     ...  c_r_x  c_r_y  c_r_z  c_r_w      name  height(cm)  speed(kg)  \\\n",
       "1    ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "2    ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "3    ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "4    ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "5    ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "..   ...    ...    ...    ...    ...       ...         ...        ...   \n",
       "895  ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "896  ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "897  ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "898  ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "899  ...    0.0    0.0    0.0    0.0  Fernando         183         94   \n",
       "\n",
       "         direction  angle    speed  \n",
       "1    one_direction      0  stopped  \n",
       "2    one_direction      0  stopped  \n",
       "3    one_direction      0  stopped  \n",
       "4    one_direction      0  stopped  \n",
       "5    one_direction      0  stopped  \n",
       "..             ...    ...      ...  \n",
       "895  one_direction      0  stopped  \n",
       "896  one_direction      0  stopped  \n",
       "897  one_direction      0  stopped  \n",
       "898  one_direction      0  stopped  \n",
       "899  one_direction      0  stopped  \n",
       "\n",
       "[899 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel_stop=data[:900].diff()[1:]\n",
    "vel_stop[\"name\"]=\"Fernando\"\n",
    "vel_stop[\"height(cm)\"]=183\n",
    "vel_stop[\"speed(kg)\"]=94\n",
    "vel_stop[\"direction\"]=\"one_direction\"\n",
    "vel_stop[\"angle\"]=\"0\"\n",
    "vel_stop[\"speed\"]=\"stopped\"\n",
    "\n",
    "\n",
    "\n",
    "vel_slow=data[900:1800].diff()[1:]\n",
    "\n",
    "\n",
    "vel_slow[\"name\"]=\"Fernando\"\n",
    "vel_slow[\"height(cm)\"]=183\n",
    "vel_slow[\"speed(kg)\"]=94\n",
    "vel_slow[\"direction\"]=\"one_direction\"\n",
    "vel_slow[\"angle\"]=\"0\"\n",
    "vel_slow[\"speed\"]=\"slow\"\n",
    "\n",
    "vel_fast=data[1800:2700].diff()[1:]\n",
    "\n",
    "\n",
    "\n",
    "vel_slow[\"name\"]=\"Fernando\"\n",
    "vel_slow[\"height(cm)\"]=183\n",
    "vel_slow[\"speed(kg)\"]=94\n",
    "vel_slow[\"direction\"]=\"one_direction\"\n",
    "vel_slow[\"angle\"]=\"0\"\n",
    "vel_slow[\"speed\"]=\"slow\"\n",
    "\n",
    "\n",
    "vel_slow2=data[2700:3600].diff()[1:]\n",
    "vel_stop2=data[3600:4500].diff()[1:]\n",
    "\n",
    "vel_stop2[\"name\"]=\"Fernando\"\n",
    "vel_stop2[\"height(cm)\"]=183\n",
    "vel_stop2[\"speed(kg)\"]=94\n",
    "vel_stop2[\"direction\"]=\"one_direction\"\n",
    "vel_stop2[\"angle\"]=\"0\"\n",
    "vel_stop2[\"speed\"]=\"stopped\"\n",
    "\n",
    "vel_fast2=data[4500:5400].diff()[1:]\n",
    "vel_stop3=data[5400:6300].diff()[1:]\n",
    "\n",
    "vel_stop2[\"name\"]=\"Fernando\"\n",
    "vel_stop2[\"height(cm)\"]=183\n",
    "vel_stop2[\"speed(kg)\"]=94\n",
    "vel_stop2[\"direction\"]=\"one_direction\"\n",
    "vel_stop2[\"angle\"]=\"0\"\n",
    "vel_stop2[\"speed\"]=\"stopped\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# f_vel_stop=data_fernando[:300]\n",
    "# f_vel_slow=data_fernando[300:600]\n",
    "# f_vel_fast=data_fernando[600:900]\n",
    "# f_vel_slow2=data_fernando[900:1200]\n",
    "# f_vel_stop2=data_fernando[1200:1500]\n",
    "# f_vel_fast2=data_fernando[1500:1800]\n",
    "# f_vel_stop3=data_fernando[1800:]\n",
    "vel_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlY3B_YnEEtI",
   "metadata": {
    "id": "mlY3B_YnEEtI"
   },
   "outputs": [],
   "source": [
    "frames_stop = [vel_stop, vel_stop2, vel_stop3]\n",
    "  \n",
    "result_stop = pd.concat(frames_stop)\n",
    "result_stop.to_csv('data/vel_parada.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NPMH8acmLE7H",
   "metadata": {
    "id": "NPMH8acmLE7H"
   },
   "outputs": [],
   "source": [
    "frames_slow = [vel_slow, vel_slow2]\n",
    "result_slow = pd.concat(frames_slow)\n",
    "result_slow.to_csv('data/vel_media.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIFLXFdGLFUd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wIFLXFdGLFUd",
    "outputId": "9215b27b-4bbe-4ca5-de2e-f5ae1cca9773"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-efd0ef8d-410f-4ad2-a33f-eba37371445d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_t_x</th>\n",
       "      <th>e_t_y</th>\n",
       "      <th>e_t_z</th>\n",
       "      <th>e_r_x</th>\n",
       "      <th>e_r_y</th>\n",
       "      <th>e_r_z</th>\n",
       "      <th>e_r_w</th>\n",
       "      <th>d_t_x</th>\n",
       "      <th>d_t_y</th>\n",
       "      <th>d_t_z</th>\n",
       "      <th>...</th>\n",
       "      <th>d_r_y</th>\n",
       "      <th>d_r_z</th>\n",
       "      <th>d_r_w</th>\n",
       "      <th>c_t_x</th>\n",
       "      <th>c_t_y</th>\n",
       "      <th>c_t_z</th>\n",
       "      <th>c_r_x</th>\n",
       "      <th>c_r_y</th>\n",
       "      <th>c_r_z</th>\n",
       "      <th>c_r_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1798 rows × 21 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efd0ef8d-410f-4ad2-a33f-eba37371445d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-efd0ef8d-410f-4ad2-a33f-eba37371445d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-efd0ef8d-410f-4ad2-a33f-eba37371445d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      e_t_x  e_t_y  e_t_z  e_r_x  e_r_y  e_r_z  e_r_w  d_t_x  d_t_y  d_t_z  \\\n",
       "1801   0.00   0.00   0.00   0.00   0.01   0.00  -0.01   0.00   0.00   0.00   \n",
       "1802   0.00   0.00  -0.01   0.00   0.01  -0.01   0.00   0.00   0.00   0.00   \n",
       "1803   0.02   0.01  -0.01  -0.03  -0.01  -0.03  -0.04   0.00   0.00   0.00   \n",
       "1804   0.05   0.01  -0.06   0.05  -0.02   0.02   0.05   0.00   0.00   0.00   \n",
       "1805   0.05   0.01  -0.06   0.05  -0.02   0.03   0.05   0.00   0.00   0.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5395   0.08  -0.01   0.09  -0.02   0.01   0.02  -0.05   0.00   0.00   0.02   \n",
       "5396   0.04  -0.01   0.06  -0.01  -0.01   0.03  -0.02   0.01   0.00   0.03   \n",
       "5397   0.01   0.00   0.01   0.00   0.01   0.01  -0.01   0.02   0.01   0.03   \n",
       "5398   0.00   0.00   0.00   0.00   0.00   0.01   0.00  -0.01   0.00  -0.01   \n",
       "5399   0.00   0.00   0.00   0.00   0.00   0.00   0.00  -0.15   0.00  -0.11   \n",
       "\n",
       "      ...  d_r_y  d_r_z  d_r_w  c_t_x  c_t_y  c_t_z  c_r_x  c_r_y  c_r_z  \\\n",
       "1801  ...   0.00   0.00  -0.01  -0.04   0.00  -0.01  -0.01   0.00   0.00   \n",
       "1802  ...   0.00   0.00   0.01  -0.02   0.00   0.00   0.00   0.00   0.01   \n",
       "1803  ...   0.00   0.00   0.00  -0.01   0.00   0.00  -0.01   0.00  -0.01   \n",
       "1804  ...   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  -0.01   \n",
       "1805  ...   0.00   0.00   0.00   0.02   0.00  -0.01   0.00   0.00   0.01   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5395  ...   0.02   0.03  -0.01   0.00   0.00   0.01   0.00   0.01   0.00   \n",
       "5396  ...   0.03   0.03  -0.02   0.00   0.00   0.01   0.00   0.01   0.01   \n",
       "5397  ...   0.01   0.03  -0.03   0.00   0.01   0.03  -0.01  -0.01   0.00   \n",
       "5398  ...  -0.05   0.03  -0.05  -0.01   0.01   0.03   0.00   0.00   0.01   \n",
       "5399  ...  -0.05  -0.12   0.12  -0.03   0.00   0.03  -0.01  -0.02   0.00   \n",
       "\n",
       "      c_r_w  \n",
       "1801   0.00  \n",
       "1802   0.01  \n",
       "1803   0.00  \n",
       "1804  -0.01  \n",
       "1805   0.00  \n",
       "...     ...  \n",
       "5395   0.01  \n",
       "5396   0.00  \n",
       "5397  -0.01  \n",
       "5398  -0.01  \n",
       "5399  -0.01  \n",
       "\n",
       "[1798 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_fast = [vel_fast, vel_fast2]\n",
    "result_fast = pd.concat(frames_fast)\n",
    "result_fast.to_csv('data/vel_rapida.txt', index=False)\n",
    "result_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1",
   "metadata": {
    "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline params.\n",
    "DATA_PATH = Path('data')\n",
    "FILENAME_FAST = 'vel_rapida.txt'\n",
    "FILENAME_SLOW = 'vel_media.txt'\n",
    "FILENAME_STOP = 'vel_parada.txt'\n",
    "NUM_TIMESTEPS = 9\n",
    "IGNORE_FRACTION = 0.1\n",
    "TEST_FRACTION = 0.25\n",
    "\n",
    "# Training params.\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52716d-1339-4484-9fd3-d5206979ba8e",
   "metadata": {
    "id": "7f52716d-1339-4484-9fd3-d5206979ba8e"
   },
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    path_stop,\n",
    "    path_fast,\n",
    "    path_slow,\n",
    "    num_timesteps,\n",
    "    ignore_fraction,\n",
    "    test_fraction,\n",
    "):\n",
    "\n",
    "    def read_and_prepare_data(\n",
    "        path,\n",
    "        class_,\n",
    "        num_timesteps,\n",
    "        ignore_fraction,\n",
    "        test_fraction,\n",
    "    ):\n",
    "\n",
    "        def split_temporally(X, test_fraction):\n",
    "            num_samples = X.shape[0]\n",
    "            num_train = int(num_samples * (1.0 - test_fraction))\n",
    "            X_train, X_test = X[:num_train], X[num_train:]\n",
    "            return X_train, X_test\n",
    "\n",
    "        def transform_into_sequences(X, num_timesteps):\n",
    "            num_samples = X.shape[0]\n",
    "            X_seq = []\n",
    "            for k in range(num_samples - num_timesteps + 1):\n",
    "                X_seq.append(X[k:(k + num_timesteps)])\n",
    "            X_seq = np.array(X_seq)\n",
    "            y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "            return X_seq, y_seq\n",
    "\n",
    "        X = pd.read_csv(path).values\n",
    "        X = X[:, [0,1,2,7,8,9]]  # Use only feet translations.\n",
    "\n",
    "        # Ignore beginning and end.\n",
    "        num_samples = X.shape[0]\n",
    "        num_ignore = int(ignore_fraction * num_samples)\n",
    "        X = X[num_ignore:-num_ignore]\n",
    "\n",
    "        # Split X temporally.\n",
    "        X_train, X_test = split_temporally(X, test_fraction)\n",
    "\n",
    "        # Transform X into short sequences.\n",
    "        X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "        X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def shuffle_data(X, y):\n",
    "        idx = np.arange(len(X))\n",
    "        default_rng().shuffle(idx)\n",
    "        X_shuffled = X[idx, :]\n",
    "        y_shuffled = y[idx]\n",
    "        return X_shuffled, y_shuffled\n",
    "\n",
    "    X_train_fast, y_train_fast, X_test_fast, y_test_fast = \\\n",
    "        read_and_prepare_data(\n",
    "            path_fast,\n",
    "            2.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train_stop, y_train_stop, X_test_stop, y_test_stop = \\\n",
    "        read_and_prepare_data(\n",
    "            path_stop,\n",
    "            0.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    X_train_slow, y_train_slow, X_test_slow, y_test_slow = \\\n",
    "        read_and_prepare_data(\n",
    "            path_slow,\n",
    "            1.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train = np.concatenate((X_train_fast, X_train_slow, X_train_stop), axis=0)\n",
    "    y_train = np.concatenate((y_train_fast, y_train_slow, y_train_stop), axis=0)\n",
    "    X_test = np.concatenate((X_test_fast, X_test_slow, X_test_stop), axis=0)\n",
    "    y_test = np.concatenate((y_test_fast, y_test_slow, y_test_stop), axis=0)\n",
    "\n",
    "    X_train, y_train = shuffle_data(X_train, y_train)\n",
    "    X_test, y_test = shuffle_data(X_test, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "path_fast = Path(DATA_PATH, FILENAME_FAST)\n",
    "path_slow = Path(DATA_PATH, FILENAME_SLOW)\n",
    "path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "X_train, X_test, y_train, y_test = load_data(\n",
    "    path_stop,\n",
    "    path_fast,\n",
    "    path_slow,\n",
    "    NUM_TIMESTEPS,\n",
    "    IGNORE_FRACTION,\n",
    "    TEST_FRACTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c35712-1089-44f3-89ef-ed471b144c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99c35712-1089-44f3-89ef-ed471b144c96",
    "outputId": "9076061a-8661-4d2e-c1ed-887a92ec640b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3755, 9, 6), (3755, 1), (1236, 9, 6), (1236, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VqSuqgBCB_nA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqSuqgBCB_nA",
    "outputId": "26d50bbe-3fd3-4bed-e70e-7003d289c5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01, -0.01,  0.  ,  0.01,  0.02, -0.05],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.01, -0.06],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.01,  0.  , -0.02],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.01,  0.03],\n",
       "       [ 0.  , -0.01,  0.  , -0.01,  0.  ,  0.05],\n",
       "       [ 0.  ,  0.01,  0.  , -0.01, -0.01,  0.05],\n",
       "       [ 0.  ,  0.  ,  0.  , -0.01,  0.  ,  0.02],\n",
       "       [ 0.  ,  0.  , -0.01, -0.01,  0.  ,  0.  ],\n",
       "       [-0.01,  0.  ,  0.  ,  0.  , -0.01,  0.  ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dye8vjENBtXX",
   "metadata": {
    "id": "dye8vjENBtXX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3TttkaRCM4l",
   "metadata": {
    "id": "-3TttkaRCM4l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85634b-4e9c-45b8-b456-cb970457302f",
   "metadata": {
    "id": "3a85634b-4e9c-45b8-b456-cb970457302f"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "_, num_time, num_feat = X_train.shape\n",
    "\n",
    "activation = 'selu'\n",
    "\n",
    "DefaultConv1D = partial(\n",
    "    keras.layers.Conv1D,\n",
    "    kernel_size=1,\n",
    "    activation=activation,\n",
    "    padding=\"valid\",\n",
    ")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv1D(4 * num_feat, kernel_size=4, input_shape=[num_time, num_feat]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConv1D(num_feat, kernel_size=3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(num_time * num_feat, activation=activation),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(num_feat, activation=activation),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0C2RSxICKzq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0C2RSxICKzq",
    "outputId": "af853522-fdf6-40e4-8d0e-cd2a6dcdab9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.01,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf8970-5318-4461-b828-d34c232afa5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7baf8970-5318-4461-b828-d34c232afa5f",
    "outputId": "08a66cc8-aeee-42ba-f039-9dfa2ba6f99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 6, 24)             600       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6, 24)            96        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 6)              438       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24)               96        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 54)                1350      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 54)               216       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 330       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6)                24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,171\n",
      "Trainable params: 2,955\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
    "outputId": "7211ef5c-5b4a-4afb-ad4f-7341eeb8f0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 11s 71ms/step - loss: 1.2607 - accuracy: 0.4578 - val_loss: 1.0764 - val_accuracy: 0.4361\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9759 - accuracy: 0.5782 - val_loss: 1.0873 - val_accuracy: 0.4304\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8031 - accuracy: 0.6493 - val_loss: 1.1070 - val_accuracy: 0.4304\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6887 - accuracy: 0.6991 - val_loss: 1.1174 - val_accuracy: 0.4304\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.7345 - val_loss: 1.1225 - val_accuracy: 0.4304\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5834 - accuracy: 0.7683 - val_loss: 1.1190 - val_accuracy: 0.4304\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5476 - accuracy: 0.8013 - val_loss: 1.1321 - val_accuracy: 0.4304\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.8194 - val_loss: 1.1549 - val_accuracy: 0.4304\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4857 - accuracy: 0.8402 - val_loss: 1.1696 - val_accuracy: 0.4304\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.8578 - val_loss: 1.1793 - val_accuracy: 0.4304\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.8740 - val_loss: 1.1903 - val_accuracy: 0.4304\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.8762 - val_loss: 1.2117 - val_accuracy: 0.4304\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3910 - accuracy: 0.8842 - val_loss: 1.2178 - val_accuracy: 0.4304\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3736 - accuracy: 0.8866 - val_loss: 1.2029 - val_accuracy: 0.4304\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3579 - accuracy: 0.8977 - val_loss: 1.2047 - val_accuracy: 0.4304\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3457 - accuracy: 0.8985 - val_loss: 1.1832 - val_accuracy: 0.4304\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3396 - accuracy: 0.9009 - val_loss: 1.1659 - val_accuracy: 0.4312\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3276 - accuracy: 0.9023 - val_loss: 1.1670 - val_accuracy: 0.4304\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3159 - accuracy: 0.9057 - val_loss: 1.1407 - val_accuracy: 0.4320\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3074 - accuracy: 0.9095 - val_loss: 1.1511 - val_accuracy: 0.4312\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2952 - accuracy: 0.9121 - val_loss: 1.1498 - val_accuracy: 0.4304\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2945 - accuracy: 0.9076 - val_loss: 1.1325 - val_accuracy: 0.4312\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2864 - accuracy: 0.9150 - val_loss: 1.1037 - val_accuracy: 0.4345\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2824 - accuracy: 0.9156 - val_loss: 1.1205 - val_accuracy: 0.4377\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2728 - accuracy: 0.9169 - val_loss: 1.1139 - val_accuracy: 0.4353\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2685 - accuracy: 0.9206 - val_loss: 1.1140 - val_accuracy: 0.4393\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2655 - accuracy: 0.9196 - val_loss: 1.0875 - val_accuracy: 0.4458\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2586 - accuracy: 0.9246 - val_loss: 1.0689 - val_accuracy: 0.4563\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.2641 - accuracy: 0.9230 - val_loss: 1.0481 - val_accuracy: 0.4539\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2577 - accuracy: 0.9217 - val_loss: 1.0844 - val_accuracy: 0.4555\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.2486 - accuracy: 0.9286 - val_loss: 1.0585 - val_accuracy: 0.4903\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2441 - accuracy: 0.9273 - val_loss: 1.0632 - val_accuracy: 0.5073\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2400 - accuracy: 0.9321 - val_loss: 1.0732 - val_accuracy: 0.5040\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2400 - accuracy: 0.9254 - val_loss: 1.0229 - val_accuracy: 0.4919\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2402 - accuracy: 0.9332 - val_loss: 1.0460 - val_accuracy: 0.5089\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2296 - accuracy: 0.9308 - val_loss: 1.0656 - val_accuracy: 0.5113\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2226 - accuracy: 0.9353 - val_loss: 1.1015 - val_accuracy: 0.5518\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2259 - accuracy: 0.9353 - val_loss: 1.0779 - val_accuracy: 0.5243\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2200 - accuracy: 0.9401 - val_loss: 1.0378 - val_accuracy: 0.5647\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2205 - accuracy: 0.9350 - val_loss: 1.0751 - val_accuracy: 0.5850\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2167 - accuracy: 0.9356 - val_loss: 1.1371 - val_accuracy: 0.5283\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2275 - accuracy: 0.9289 - val_loss: 1.1327 - val_accuracy: 0.5825\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2157 - accuracy: 0.9329 - val_loss: 1.1426 - val_accuracy: 0.6246\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2117 - accuracy: 0.9393 - val_loss: 1.2123 - val_accuracy: 0.6173\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2057 - accuracy: 0.9417 - val_loss: 1.1760 - val_accuracy: 0.6270\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2084 - accuracy: 0.9366 - val_loss: 1.0994 - val_accuracy: 0.6165\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2009 - accuracy: 0.9422 - val_loss: 1.0200 - val_accuracy: 0.6189\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1961 - accuracy: 0.9409 - val_loss: 1.0586 - val_accuracy: 0.5987\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1954 - accuracy: 0.9411 - val_loss: 1.0459 - val_accuracy: 0.5396\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.1940 - accuracy: 0.9422 - val_loss: 1.1150 - val_accuracy: 0.6230\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.1868 - accuracy: 0.9465 - val_loss: 1.1235 - val_accuracy: 0.6262\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1880 - accuracy: 0.9470 - val_loss: 0.9952 - val_accuracy: 0.6375\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1900 - accuracy: 0.9433 - val_loss: 0.9190 - val_accuracy: 0.6602\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1796 - accuracy: 0.9497 - val_loss: 1.0315 - val_accuracy: 0.6545\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1816 - accuracy: 0.9457 - val_loss: 1.0818 - val_accuracy: 0.6683\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1787 - accuracy: 0.9486 - val_loss: 1.0050 - val_accuracy: 0.6723\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1773 - accuracy: 0.9491 - val_loss: 0.9688 - val_accuracy: 0.6780\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1785 - accuracy: 0.9499 - val_loss: 0.9209 - val_accuracy: 0.6828\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 1.0628 - val_accuracy: 0.6812\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1795 - accuracy: 0.9470 - val_loss: 0.7832 - val_accuracy: 0.6974\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1759 - accuracy: 0.9475 - val_loss: 0.8206 - val_accuracy: 0.6845\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1754 - accuracy: 0.9475 - val_loss: 0.9722 - val_accuracy: 0.6553\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1677 - accuracy: 0.9534 - val_loss: 1.0638 - val_accuracy: 0.6634\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1703 - accuracy: 0.9499 - val_loss: 0.6678 - val_accuracy: 0.7120\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1721 - accuracy: 0.9478 - val_loss: 0.6714 - val_accuracy: 0.7257\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1670 - accuracy: 0.9521 - val_loss: 0.7640 - val_accuracy: 0.7160\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9499 - val_loss: 0.7054 - val_accuracy: 0.7330\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9515 - val_loss: 0.7411 - val_accuracy: 0.7023\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1585 - accuracy: 0.9539 - val_loss: 0.6137 - val_accuracy: 0.7613\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1602 - accuracy: 0.9555 - val_loss: 0.5638 - val_accuracy: 0.7888\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1605 - accuracy: 0.9539 - val_loss: 0.5435 - val_accuracy: 0.7824\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1586 - accuracy: 0.9547 - val_loss: 0.6876 - val_accuracy: 0.7193\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9537 - val_loss: 0.6280 - val_accuracy: 0.7451\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1547 - accuracy: 0.9579 - val_loss: 0.5197 - val_accuracy: 0.8139\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9566 - val_loss: 0.4419 - val_accuracy: 0.8269\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 0.9587 - val_loss: 0.4404 - val_accuracy: 0.8228\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.9595 - val_loss: 0.5313 - val_accuracy: 0.8244\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1487 - accuracy: 0.9566 - val_loss: 0.3997 - val_accuracy: 0.8455\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.9590 - val_loss: 0.2527 - val_accuracy: 0.8964\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.9571 - val_loss: 0.3580 - val_accuracy: 0.8641\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9614 - val_loss: 0.3005 - val_accuracy: 0.8932\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1440 - accuracy: 0.9601 - val_loss: 0.2756 - val_accuracy: 0.9021\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1417 - accuracy: 0.9587 - val_loss: 0.5619 - val_accuracy: 0.7735\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1398 - accuracy: 0.9603 - val_loss: 0.3075 - val_accuracy: 0.8803\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1426 - accuracy: 0.9582 - val_loss: 0.3193 - val_accuracy: 0.8730\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1435 - accuracy: 0.9595 - val_loss: 0.2305 - val_accuracy: 0.9142\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.9579 - val_loss: 0.2319 - val_accuracy: 0.8989\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1440 - accuracy: 0.9582 - val_loss: 0.3636 - val_accuracy: 0.8649\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.9614 - val_loss: 0.3991 - val_accuracy: 0.8414\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1421 - accuracy: 0.9593 - val_loss: 0.3255 - val_accuracy: 0.8673\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9643 - val_loss: 0.2793 - val_accuracy: 0.8948\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9622 - val_loss: 0.2064 - val_accuracy: 0.9264\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1415 - accuracy: 0.9577 - val_loss: 0.2213 - val_accuracy: 0.9264\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1313 - accuracy: 0.9619 - val_loss: 0.3973 - val_accuracy: 0.8811\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.9632 - val_loss: 0.2166 - val_accuracy: 0.9207\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1319 - accuracy: 0.9630 - val_loss: 0.4696 - val_accuracy: 0.8617\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9651 - val_loss: 0.2042 - val_accuracy: 0.9264\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1239 - accuracy: 0.9656 - val_loss: 0.2458 - val_accuracy: 0.8972\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1225 - accuracy: 0.9651 - val_loss: 0.2617 - val_accuracy: 0.8972\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9694 - val_loss: 0.2281 - val_accuracy: 0.9142\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1234 - accuracy: 0.9648 - val_loss: 0.2740 - val_accuracy: 0.8989\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1283 - accuracy: 0.9625 - val_loss: 0.4094 - val_accuracy: 0.8528\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1280 - accuracy: 0.9651 - val_loss: 0.2776 - val_accuracy: 0.9142\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1244 - accuracy: 0.9659 - val_loss: 0.2632 - val_accuracy: 0.8997\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9590 - val_loss: 0.2862 - val_accuracy: 0.8997\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1387 - accuracy: 0.9569 - val_loss: 0.2865 - val_accuracy: 0.8956\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.3543 - val_accuracy: 0.8714\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.9648 - val_loss: 0.2248 - val_accuracy: 0.9239\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.9670 - val_loss: 0.2493 - val_accuracy: 0.9175\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9712 - val_loss: 0.2500 - val_accuracy: 0.9013\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1143 - accuracy: 0.9702 - val_loss: 0.2454 - val_accuracy: 0.9110\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9680 - val_loss: 0.2361 - val_accuracy: 0.9256\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1203 - accuracy: 0.9680 - val_loss: 0.2924 - val_accuracy: 0.9142\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1145 - accuracy: 0.9699 - val_loss: 0.2311 - val_accuracy: 0.9118\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9662 - val_loss: 0.2583 - val_accuracy: 0.9191\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.9632 - val_loss: 1.0513 - val_accuracy: 0.5291\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.9664 - val_loss: 0.8966 - val_accuracy: 0.5453\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1207 - accuracy: 0.9683 - val_loss: 0.7388 - val_accuracy: 0.6076\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9601 - val_loss: 0.3638 - val_accuracy: 0.8981\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.5089 - val_accuracy: 0.8317\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9696 - val_loss: 0.4506 - val_accuracy: 0.8633\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1082 - accuracy: 0.9728 - val_loss: 0.4639 - val_accuracy: 0.8430\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1091 - accuracy: 0.9704 - val_loss: 0.2277 - val_accuracy: 0.9231\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1046 - accuracy: 0.9728 - val_loss: 0.2467 - val_accuracy: 0.9150\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1052 - accuracy: 0.9739 - val_loss: 0.2299 - val_accuracy: 0.9312\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9736 - val_loss: 0.5344 - val_accuracy: 0.8528\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1038 - accuracy: 0.9731 - val_loss: 0.2632 - val_accuracy: 0.9053\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1105 - accuracy: 0.9715 - val_loss: 0.3382 - val_accuracy: 0.8940\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1089 - accuracy: 0.9696 - val_loss: 0.2734 - val_accuracy: 0.9118\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1131 - accuracy: 0.9688 - val_loss: 1.3419 - val_accuracy: 0.5121\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1116 - accuracy: 0.9680 - val_loss: 0.2947 - val_accuracy: 0.9005\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1194 - accuracy: 0.9664 - val_loss: 0.6178 - val_accuracy: 0.8107\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.9614 - val_loss: 2.1854 - val_accuracy: 0.5170\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1280 - accuracy: 0.9635 - val_loss: 0.4732 - val_accuracy: 0.8519\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1218 - accuracy: 0.9646 - val_loss: 0.8336 - val_accuracy: 0.6084\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1081 - accuracy: 0.9696 - val_loss: 0.2125 - val_accuracy: 0.9256\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1030 - accuracy: 0.9715 - val_loss: 0.2932 - val_accuracy: 0.9078\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1102 - accuracy: 0.9699 - val_loss: 0.3043 - val_accuracy: 0.9086\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1069 - accuracy: 0.9734 - val_loss: 1.2877 - val_accuracy: 0.5259\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1065 - accuracy: 0.9715 - val_loss: 1.5241 - val_accuracy: 0.5235\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9731 - val_loss: 0.6994 - val_accuracy: 0.6181\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1105 - accuracy: 0.9664 - val_loss: 0.6139 - val_accuracy: 0.8439\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.9726 - val_loss: 0.2484 - val_accuracy: 0.9159\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 0.9726 - val_loss: 0.5081 - val_accuracy: 0.8681\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0969 - accuracy: 0.9760 - val_loss: 0.3657 - val_accuracy: 0.8981\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0977 - accuracy: 0.9760 - val_loss: 0.6001 - val_accuracy: 0.8463\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0964 - accuracy: 0.9744 - val_loss: 0.6247 - val_accuracy: 0.8236\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0973 - accuracy: 0.9742 - val_loss: 0.3265 - val_accuracy: 0.9029\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0954 - accuracy: 0.9742 - val_loss: 0.4114 - val_accuracy: 0.8883\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0946 - accuracy: 0.9776 - val_loss: 0.3014 - val_accuracy: 0.9029\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9744 - val_loss: 0.9162 - val_accuracy: 0.5461\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.9718 - val_loss: 0.3001 - val_accuracy: 0.9013\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.9774 - val_loss: 0.3197 - val_accuracy: 0.9110\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 0.9798 - val_loss: 0.2441 - val_accuracy: 0.9239\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9747 - val_loss: 0.3690 - val_accuracy: 0.8924\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0957 - accuracy: 0.9758 - val_loss: 2.8835 - val_accuracy: 0.5243\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9766 - val_loss: 2.0856 - val_accuracy: 0.5227\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.9779 - val_loss: 1.5690 - val_accuracy: 0.5324\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 0.9768 - val_loss: 1.8585 - val_accuracy: 0.5275\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0887 - accuracy: 0.9792 - val_loss: 0.8379 - val_accuracy: 0.5769\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0973 - accuracy: 0.9755 - val_loss: 0.3025 - val_accuracy: 0.9053\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0948 - accuracy: 0.9760 - val_loss: 0.3693 - val_accuracy: 0.8916\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9699 - val_loss: 0.9631 - val_accuracy: 0.7718\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0933 - accuracy: 0.9760 - val_loss: 0.5282 - val_accuracy: 0.8625\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1016 - accuracy: 0.9712 - val_loss: 0.4952 - val_accuracy: 0.8584\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1039 - accuracy: 0.9691 - val_loss: 0.3189 - val_accuracy: 0.9094\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9752 - val_loss: 0.4155 - val_accuracy: 0.8956\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 0.9774 - val_loss: 0.6023 - val_accuracy: 0.8560\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9760 - val_loss: 0.3267 - val_accuracy: 0.9021\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9742 - val_loss: 0.3958 - val_accuracy: 0.8989\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1029 - accuracy: 0.9718 - val_loss: 0.3716 - val_accuracy: 0.9070\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.9760 - val_loss: 0.4890 - val_accuracy: 0.8584\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.9790 - val_loss: 0.6538 - val_accuracy: 0.8374\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 0.9768 - val_loss: 0.3508 - val_accuracy: 0.9167\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.9782 - val_loss: 0.3807 - val_accuracy: 0.9045\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0890 - accuracy: 0.9784 - val_loss: 0.9478 - val_accuracy: 0.5510\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9742 - val_loss: 0.3331 - val_accuracy: 0.8948\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0992 - accuracy: 0.9712 - val_loss: 0.5526 - val_accuracy: 0.8738\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.9723 - val_loss: 0.7290 - val_accuracy: 0.8180\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 0.9734 - val_loss: 0.4098 - val_accuracy: 0.9005\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9782 - val_loss: 0.4152 - val_accuracy: 0.8964\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9806 - val_loss: 0.6970 - val_accuracy: 0.6537\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9830 - val_loss: 0.3488 - val_accuracy: 0.8827\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9795 - val_loss: 0.2894 - val_accuracy: 0.9070\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9811 - val_loss: 0.4313 - val_accuracy: 0.8754\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9792 - val_loss: 0.5583 - val_accuracy: 0.8665\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9798 - val_loss: 0.4926 - val_accuracy: 0.8657\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0818 - accuracy: 0.9811 - val_loss: 0.2988 - val_accuracy: 0.9053\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9824 - val_loss: 0.5059 - val_accuracy: 0.8746\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9768 - val_loss: 0.3834 - val_accuracy: 0.8932\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0812 - accuracy: 0.9808 - val_loss: 0.3372 - val_accuracy: 0.9005\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9827 - val_loss: 0.3867 - val_accuracy: 0.8900\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9803 - val_loss: 0.4514 - val_accuracy: 0.8738\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9824 - val_loss: 0.4119 - val_accuracy: 0.8948\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0855 - accuracy: 0.9766 - val_loss: 0.7322 - val_accuracy: 0.8034\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9795 - val_loss: 0.3433 - val_accuracy: 0.9021\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0853 - accuracy: 0.9774 - val_loss: 0.4752 - val_accuracy: 0.8762\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0989 - accuracy: 0.9696 - val_loss: 0.3982 - val_accuracy: 0.8851\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 0.9758 - val_loss: 2.5531 - val_accuracy: 0.5243\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9768 - val_loss: 0.3370 - val_accuracy: 0.9029\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0885 - accuracy: 0.9766 - val_loss: 0.3422 - val_accuracy: 0.9070\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9787 - val_loss: 0.4335 - val_accuracy: 0.8875\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9784 - val_loss: 0.4102 - val_accuracy: 0.8908\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0780 - accuracy: 0.9824 - val_loss: 0.3667 - val_accuracy: 0.8972\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9787 - val_loss: 0.5498 - val_accuracy: 0.8617\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9803 - val_loss: 0.7267 - val_accuracy: 0.7913\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9811 - val_loss: 0.6002 - val_accuracy: 0.8552\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0784 - accuracy: 0.9811 - val_loss: 0.5824 - val_accuracy: 0.8625\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0792 - accuracy: 0.9808 - val_loss: 0.4850 - val_accuracy: 0.8803\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0771 - accuracy: 0.9806 - val_loss: 0.6480 - val_accuracy: 0.8074\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0744 - accuracy: 0.9843 - val_loss: 0.4011 - val_accuracy: 0.8916\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0771 - accuracy: 0.9814 - val_loss: 0.3067 - val_accuracy: 0.9142\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9758 - val_loss: 0.6399 - val_accuracy: 0.8552\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 0.9763 - val_loss: 0.8787 - val_accuracy: 0.8018\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0918 - accuracy: 0.9734 - val_loss: 0.4494 - val_accuracy: 0.8811\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0966 - accuracy: 0.9712 - val_loss: 0.3074 - val_accuracy: 0.9118\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 0.9752 - val_loss: 0.7785 - val_accuracy: 0.8204\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9787 - val_loss: 0.3168 - val_accuracy: 0.9037\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9798 - val_loss: 0.3394 - val_accuracy: 0.9118\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9814 - val_loss: 1.4788 - val_accuracy: 0.5307\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0731 - accuracy: 0.9840 - val_loss: 0.9227 - val_accuracy: 0.5639\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0733 - accuracy: 0.9832 - val_loss: 0.3733 - val_accuracy: 0.9037\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0799 - accuracy: 0.9790 - val_loss: 0.3937 - val_accuracy: 0.9070\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9806 - val_loss: 0.7508 - val_accuracy: 0.8220\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0757 - accuracy: 0.9827 - val_loss: 0.4191 - val_accuracy: 0.8932\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9840 - val_loss: 0.6036 - val_accuracy: 0.8528\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9827 - val_loss: 1.5702 - val_accuracy: 0.5340\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9811 - val_loss: 0.7063 - val_accuracy: 0.8406\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9803 - val_loss: 0.5568 - val_accuracy: 0.8641\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9814 - val_loss: 0.4622 - val_accuracy: 0.8730\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0710 - accuracy: 0.9851 - val_loss: 0.3256 - val_accuracy: 0.9086\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9848 - val_loss: 0.4061 - val_accuracy: 0.8900\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0693 - accuracy: 0.9846 - val_loss: 0.4279 - val_accuracy: 0.9061\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9816 - val_loss: 0.9644 - val_accuracy: 0.8042\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 0.9856 - val_loss: 0.4704 - val_accuracy: 0.8803\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 0.3891 - val_accuracy: 0.8981\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0719 - accuracy: 0.9838 - val_loss: 0.3932 - val_accuracy: 0.8972\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0702 - accuracy: 0.9835 - val_loss: 0.3756 - val_accuracy: 0.8989\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0699 - accuracy: 0.9824 - val_loss: 0.8019 - val_accuracy: 0.8261\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0704 - accuracy: 0.9843 - val_loss: 1.0680 - val_accuracy: 0.5574\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0685 - accuracy: 0.9840 - val_loss: 0.3225 - val_accuracy: 0.9013\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0783 - accuracy: 0.9803 - val_loss: 0.3789 - val_accuracy: 0.9005\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0725 - accuracy: 0.9816 - val_loss: 2.1511 - val_accuracy: 0.7120\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9838 - val_loss: 1.8147 - val_accuracy: 0.7233\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0703 - accuracy: 0.9848 - val_loss: 0.5140 - val_accuracy: 0.8770\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9835 - val_loss: 0.4913 - val_accuracy: 0.8770\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0713 - accuracy: 0.9848 - val_loss: 1.4608 - val_accuracy: 0.7451\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9787 - val_loss: 1.1549 - val_accuracy: 0.5445\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0771 - accuracy: 0.9798 - val_loss: 0.3145 - val_accuracy: 0.9175\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0785 - accuracy: 0.9798 - val_loss: 0.3117 - val_accuracy: 0.9215\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.9795 - val_loss: 2.2130 - val_accuracy: 0.5316\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9707 - val_loss: 4.1039 - val_accuracy: 0.5154\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0991 - accuracy: 0.9688 - val_loss: 2.6434 - val_accuracy: 0.5170\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9734 - val_loss: 0.9431 - val_accuracy: 0.5688\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0853 - accuracy: 0.9744 - val_loss: 0.3203 - val_accuracy: 0.9183\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9811 - val_loss: 1.2955 - val_accuracy: 0.7718\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9819 - val_loss: 0.5266 - val_accuracy: 0.8770\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.9846 - val_loss: 0.4230 - val_accuracy: 0.8908\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 0.9846 - val_loss: 0.3151 - val_accuracy: 0.9159\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9854 - val_loss: 0.7307 - val_accuracy: 0.8228\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0671 - accuracy: 0.9835 - val_loss: 0.2924 - val_accuracy: 0.9207\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0668 - accuracy: 0.9832 - val_loss: 0.3256 - val_accuracy: 0.9110\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0678 - accuracy: 0.9851 - val_loss: 0.4989 - val_accuracy: 0.8851\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9816 - val_loss: 0.2714 - val_accuracy: 0.9231\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0736 - accuracy: 0.9806 - val_loss: 1.1801 - val_accuracy: 0.7775\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0760 - accuracy: 0.9800 - val_loss: 0.5538 - val_accuracy: 0.8811\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9782 - val_loss: 0.5217 - val_accuracy: 0.8803\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0784 - accuracy: 0.9787 - val_loss: 0.5270 - val_accuracy: 0.8843\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0809 - accuracy: 0.9774 - val_loss: 0.4262 - val_accuracy: 0.8948\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 2.6196 - val_accuracy: 0.7128\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0728 - accuracy: 0.9827 - val_loss: 1.0533 - val_accuracy: 0.7937\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 0.9851 - val_loss: 1.0847 - val_accuracy: 0.7921\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0644 - accuracy: 0.9867 - val_loss: 1.2140 - val_accuracy: 0.7718\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0651 - accuracy: 0.9862 - val_loss: 0.9087 - val_accuracy: 0.7694\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9862 - val_loss: 1.5409 - val_accuracy: 0.5267\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9843 - val_loss: 0.4516 - val_accuracy: 0.8908\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0651 - accuracy: 0.9835 - val_loss: 0.5844 - val_accuracy: 0.8617\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.9846 - val_loss: 0.3597 - val_accuracy: 0.9029\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0640 - accuracy: 0.9859 - val_loss: 0.7133 - val_accuracy: 0.8503\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0624 - accuracy: 0.9862 - val_loss: 0.5966 - val_accuracy: 0.8455\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0668 - accuracy: 0.9840 - val_loss: 0.2605 - val_accuracy: 0.9183\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9859 - val_loss: 0.6733 - val_accuracy: 0.8487\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.9854 - val_loss: 0.5369 - val_accuracy: 0.8738\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 0.9848 - val_loss: 0.4183 - val_accuracy: 0.8989\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9859 - val_loss: 0.3807 - val_accuracy: 0.9070\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 0.9848 - val_loss: 0.7730 - val_accuracy: 0.6173\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9846 - val_loss: 0.4082 - val_accuracy: 0.8972\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0644 - accuracy: 0.9848 - val_loss: 0.9732 - val_accuracy: 0.8050\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0643 - accuracy: 0.9854 - val_loss: 0.5667 - val_accuracy: 0.8681\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 0.9864 - val_loss: 0.4688 - val_accuracy: 0.8940\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0590 - accuracy: 0.9883 - val_loss: 0.5436 - val_accuracy: 0.8673\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9859 - val_loss: 0.2996 - val_accuracy: 0.9175\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9856 - val_loss: 0.2834 - val_accuracy: 0.9167\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9872 - val_loss: 0.3252 - val_accuracy: 0.9167\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0587 - accuracy: 0.9872 - val_loss: 0.4998 - val_accuracy: 0.8875\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9843 - val_loss: 0.5136 - val_accuracy: 0.8835\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0615 - accuracy: 0.9864 - val_loss: 0.8886 - val_accuracy: 0.6230\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9840 - val_loss: 0.3236 - val_accuracy: 0.9183\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9859 - val_loss: 0.8518 - val_accuracy: 0.6424\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9870 - val_loss: 0.4305 - val_accuracy: 0.9102\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9867 - val_loss: 0.5990 - val_accuracy: 0.8649\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9872 - val_loss: 1.1136 - val_accuracy: 0.7759\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9862 - val_loss: 0.7332 - val_accuracy: 0.8261\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9880 - val_loss: 0.4046 - val_accuracy: 0.9078\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9875 - val_loss: 0.5194 - val_accuracy: 0.8843\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9859 - val_loss: 0.6498 - val_accuracy: 0.8584\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9859 - val_loss: 0.2755 - val_accuracy: 0.9231\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.2286 - val_accuracy: 0.9353\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9867 - val_loss: 0.3436 - val_accuracy: 0.9199\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9880 - val_loss: 1.2111 - val_accuracy: 0.5639\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0604 - accuracy: 0.9862 - val_loss: 0.7123 - val_accuracy: 0.8439\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9859 - val_loss: 0.6936 - val_accuracy: 0.8625\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 0.9838 - val_loss: 0.3971 - val_accuracy: 0.9005\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9851 - val_loss: 0.3899 - val_accuracy: 0.8892\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9859 - val_loss: 0.3277 - val_accuracy: 0.9110\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.9856 - val_loss: 0.3507 - val_accuracy: 0.9118\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0672 - accuracy: 0.9838 - val_loss: 0.5645 - val_accuracy: 0.8835\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0644 - accuracy: 0.9848 - val_loss: 0.6267 - val_accuracy: 0.8689\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9843 - val_loss: 0.5565 - val_accuracy: 0.8633\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.9838 - val_loss: 0.6110 - val_accuracy: 0.8665\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0643 - accuracy: 0.9846 - val_loss: 0.6447 - val_accuracy: 0.8625\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9830 - val_loss: 0.3405 - val_accuracy: 0.9215\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.9840 - val_loss: 0.7311 - val_accuracy: 0.8617\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 0.9803 - val_loss: 0.4404 - val_accuracy: 0.9159\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.9790 - val_loss: 0.4081 - val_accuracy: 0.9037\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9776 - val_loss: 0.6820 - val_accuracy: 0.8730\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9744 - val_loss: 0.9811 - val_accuracy: 0.8430\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0854 - accuracy: 0.9752 - val_loss: 5.2254 - val_accuracy: 0.5291\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9763 - val_loss: 2.8158 - val_accuracy: 0.5332\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0848 - accuracy: 0.9766 - val_loss: 0.3449 - val_accuracy: 0.9191\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.4571 - val_accuracy: 0.9070\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.8246 - val_accuracy: 0.8220\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0645 - accuracy: 0.9838 - val_loss: 0.5642 - val_accuracy: 0.8746\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9854 - val_loss: 0.4868 - val_accuracy: 0.8981\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9880 - val_loss: 3.0020 - val_accuracy: 0.5324\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 0.9877 - val_loss: 2.2230 - val_accuracy: 0.5380\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0593 - accuracy: 0.9856 - val_loss: 0.3752 - val_accuracy: 0.9045\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9870 - val_loss: 0.4995 - val_accuracy: 0.8900\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 0.9883 - val_loss: 0.5618 - val_accuracy: 0.8689\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9888 - val_loss: 1.1295 - val_accuracy: 0.7896\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 0.9885 - val_loss: 0.4349 - val_accuracy: 0.8972\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9870 - val_loss: 0.6806 - val_accuracy: 0.8455\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 0.9883 - val_loss: 1.1468 - val_accuracy: 0.7913\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9864 - val_loss: 0.9625 - val_accuracy: 0.8188\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0560 - accuracy: 0.9877 - val_loss: 1.2563 - val_accuracy: 0.7799\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9870 - val_loss: 0.7631 - val_accuracy: 0.8536\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9875 - val_loss: 0.4063 - val_accuracy: 0.9078\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.9859 - val_loss: 0.5171 - val_accuracy: 0.8981\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9859 - val_loss: 0.4991 - val_accuracy: 0.8803\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0574 - accuracy: 0.9872 - val_loss: 1.7398 - val_accuracy: 0.5372\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9856 - val_loss: 0.9132 - val_accuracy: 0.8285\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0604 - accuracy: 0.9862 - val_loss: 0.5394 - val_accuracy: 0.8738\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9880 - val_loss: 0.3904 - val_accuracy: 0.9061\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9877 - val_loss: 0.3224 - val_accuracy: 0.9231\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0547 - accuracy: 0.9885 - val_loss: 0.3751 - val_accuracy: 0.9061\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9899 - val_loss: 0.3915 - val_accuracy: 0.9167\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9899 - val_loss: 1.0428 - val_accuracy: 0.7945\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9872 - val_loss: 0.3932 - val_accuracy: 0.9037\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.9846 - val_loss: 0.4529 - val_accuracy: 0.9061\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9838 - val_loss: 0.4661 - val_accuracy: 0.8972\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9851 - val_loss: 0.4104 - val_accuracy: 0.8997\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0617 - accuracy: 0.9848 - val_loss: 0.7215 - val_accuracy: 0.8414\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9862 - val_loss: 0.4245 - val_accuracy: 0.9159\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9862 - val_loss: 0.3021 - val_accuracy: 0.9256\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 0.9880 - val_loss: 0.7364 - val_accuracy: 0.8471\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9893 - val_loss: 0.4232 - val_accuracy: 0.9013\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0540 - accuracy: 0.9896 - val_loss: 0.5412 - val_accuracy: 0.8794\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0516 - accuracy: 0.9888 - val_loss: 1.1905 - val_accuracy: 0.5704\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9891 - val_loss: 0.3872 - val_accuracy: 0.9053\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 0.9904 - val_loss: 0.4986 - val_accuracy: 0.8786\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9904 - val_loss: 0.6410 - val_accuracy: 0.8730\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9891 - val_loss: 0.3858 - val_accuracy: 0.9086\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0534 - accuracy: 0.9880 - val_loss: 0.6015 - val_accuracy: 0.8778\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 0.9888 - val_loss: 0.8216 - val_accuracy: 0.8382\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9883 - val_loss: 0.4083 - val_accuracy: 0.9086\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9872 - val_loss: 1.2571 - val_accuracy: 0.7872\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9896 - val_loss: 0.4813 - val_accuracy: 0.8867\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9880 - val_loss: 0.9660 - val_accuracy: 0.6019\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.9864 - val_loss: 1.0664 - val_accuracy: 0.5866\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0502 - accuracy: 0.9896 - val_loss: 0.5166 - val_accuracy: 0.8770\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9891 - val_loss: 0.7925 - val_accuracy: 0.6222\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9883 - val_loss: 0.3255 - val_accuracy: 0.9207\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0500 - accuracy: 0.9896 - val_loss: 0.4116 - val_accuracy: 0.9118\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9899 - val_loss: 0.3895 - val_accuracy: 0.9134\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 0.9896 - val_loss: 0.8380 - val_accuracy: 0.6343\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9888 - val_loss: 0.5829 - val_accuracy: 0.8819\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9862 - val_loss: 5.1536 - val_accuracy: 0.5210\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0639 - accuracy: 0.9851 - val_loss: 1.4339 - val_accuracy: 0.7686\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 0.9782 - val_loss: 0.6430 - val_accuracy: 0.8689\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9819 - val_loss: 0.8857 - val_accuracy: 0.8528\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9856 - val_loss: 1.1613 - val_accuracy: 0.7994\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9875 - val_loss: 0.3791 - val_accuracy: 0.9175\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 0.5167 - val_accuracy: 0.8819\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0630 - accuracy: 0.9862 - val_loss: 0.3158 - val_accuracy: 0.9199\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0596 - accuracy: 0.9856 - val_loss: 1.2285 - val_accuracy: 0.7872\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9846 - val_loss: 0.4448 - val_accuracy: 0.9021\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9883 - val_loss: 0.4535 - val_accuracy: 0.9013\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9885 - val_loss: 0.4869 - val_accuracy: 0.9061\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9867 - val_loss: 1.6492 - val_accuracy: 0.5316\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9856 - val_loss: 3.0137 - val_accuracy: 0.5307\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0629 - accuracy: 0.9835 - val_loss: 0.6307 - val_accuracy: 0.6820\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9862 - val_loss: 0.6847 - val_accuracy: 0.8762\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 0.9877 - val_loss: 0.7015 - val_accuracy: 0.8786\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9864 - val_loss: 0.3439 - val_accuracy: 0.9126\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9883 - val_loss: 0.6197 - val_accuracy: 0.8681\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9896 - val_loss: 0.4353 - val_accuracy: 0.9126\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 0.9891 - val_loss: 0.3197 - val_accuracy: 0.9215\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 0.9891 - val_loss: 0.4068 - val_accuracy: 0.9159\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9880 - val_loss: 0.4900 - val_accuracy: 0.8932\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0802 - accuracy: 0.9803 - val_loss: 0.4558 - val_accuracy: 0.9078\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9800 - val_loss: 0.6751 - val_accuracy: 0.8617\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0603 - accuracy: 0.9848 - val_loss: 0.8330 - val_accuracy: 0.8560\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 0.9859 - val_loss: 0.7417 - val_accuracy: 0.8665\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9864 - val_loss: 1.0175 - val_accuracy: 0.5785\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 0.9870 - val_loss: 2.0310 - val_accuracy: 0.5429\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 0.9877 - val_loss: 2.8072 - val_accuracy: 0.5307\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0531 - accuracy: 0.9883 - val_loss: 3.3022 - val_accuracy: 0.5291\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9891 - val_loss: 0.3139 - val_accuracy: 0.9328\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9880 - val_loss: 0.9293 - val_accuracy: 0.6011\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9896 - val_loss: 0.3559 - val_accuracy: 0.9086\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0523 - accuracy: 0.9883 - val_loss: 0.3158 - val_accuracy: 0.9223\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0485 - accuracy: 0.9899 - val_loss: 0.4409 - val_accuracy: 0.8940\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 0.9885 - val_loss: 0.4983 - val_accuracy: 0.8819\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9899 - val_loss: 1.1257 - val_accuracy: 0.8083\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.9888 - val_loss: 1.1869 - val_accuracy: 0.8034\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9904 - val_loss: 2.4171 - val_accuracy: 0.7201\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9877 - val_loss: 0.3310 - val_accuracy: 0.9159\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 1.7441 - val_accuracy: 0.7581\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 0.9883 - val_loss: 0.6106 - val_accuracy: 0.8762\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0488 - accuracy: 0.9901 - val_loss: 0.4423 - val_accuracy: 0.8997\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9899 - val_loss: 0.3378 - val_accuracy: 0.9215\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9888 - val_loss: 0.5174 - val_accuracy: 0.8786\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9891 - val_loss: 0.3008 - val_accuracy: 0.9183\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9846 - val_loss: 0.5998 - val_accuracy: 0.8681\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 0.9896 - val_loss: 1.2319 - val_accuracy: 0.8050\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9864 - val_loss: 0.8817 - val_accuracy: 0.6294\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9854 - val_loss: 1.0329 - val_accuracy: 0.8463\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9885 - val_loss: 1.9939 - val_accuracy: 0.7476\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0527 - accuracy: 0.9870 - val_loss: 0.5923 - val_accuracy: 0.8827\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9891 - val_loss: 0.7038 - val_accuracy: 0.8746\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0528 - accuracy: 0.9883 - val_loss: 0.7805 - val_accuracy: 0.8511\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9899 - val_loss: 0.7143 - val_accuracy: 0.8649\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0477 - accuracy: 0.9904 - val_loss: 0.4650 - val_accuracy: 0.9078\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0489 - accuracy: 0.9888 - val_loss: 0.5722 - val_accuracy: 0.8916\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9901 - val_loss: 0.4647 - val_accuracy: 0.9094\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 0.9888 - val_loss: 0.4157 - val_accuracy: 0.9037\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9877 - val_loss: 0.9878 - val_accuracy: 0.8317\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0479 - accuracy: 0.9896 - val_loss: 0.6960 - val_accuracy: 0.8600\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9901 - val_loss: 1.1419 - val_accuracy: 0.8107\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9891 - val_loss: 0.8932 - val_accuracy: 0.8261\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9872 - val_loss: 0.8731 - val_accuracy: 0.6489\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9867 - val_loss: 0.5835 - val_accuracy: 0.8706\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.9872 - val_loss: 1.6050 - val_accuracy: 0.5477\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 0.9824 - val_loss: 0.4582 - val_accuracy: 0.9070\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9870 - val_loss: 0.4848 - val_accuracy: 0.9013\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9883 - val_loss: 0.8045 - val_accuracy: 0.8511\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.7838 - val_accuracy: 0.8633\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0587 - accuracy: 0.9854 - val_loss: 0.5110 - val_accuracy: 0.9086\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.9846 - val_loss: 0.3182 - val_accuracy: 0.9239\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9867 - val_loss: 0.3648 - val_accuracy: 0.9239\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9904 - val_loss: 1.3327 - val_accuracy: 0.7735\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 0.9899 - val_loss: 0.7511 - val_accuracy: 0.8414\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.5074 - val_accuracy: 0.8827\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.9880 - val_loss: 0.4615 - val_accuracy: 0.8875\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9899 - val_loss: 0.3874 - val_accuracy: 0.9248\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9909 - val_loss: 0.2590 - val_accuracy: 0.9417\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 0.9899 - val_loss: 0.5846 - val_accuracy: 0.8608\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 0.9888 - val_loss: 1.1882 - val_accuracy: 0.7913\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9893 - val_loss: 0.3838 - val_accuracy: 0.9167\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9877 - val_loss: 1.7763 - val_accuracy: 0.7589\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9854 - val_loss: 0.4472 - val_accuracy: 0.9110\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9856 - val_loss: 1.3975 - val_accuracy: 0.7791\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0617 - accuracy: 0.9832 - val_loss: 1.0619 - val_accuracy: 0.8382\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9840 - val_loss: 0.7599 - val_accuracy: 0.8649\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9877 - val_loss: 1.1600 - val_accuracy: 0.8123\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0523 - accuracy: 0.9862 - val_loss: 1.1360 - val_accuracy: 0.8172\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9867 - val_loss: 1.0988 - val_accuracy: 0.8091\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9872 - val_loss: 0.4046 - val_accuracy: 0.9110\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.4396 - val_accuracy: 0.9110\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 0.9893 - val_loss: 3.9744 - val_accuracy: 0.5291\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0456 - accuracy: 0.9909 - val_loss: 1.4243 - val_accuracy: 0.5696\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.7888 - val_accuracy: 0.6456\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0491 - accuracy: 0.9893 - val_loss: 0.3395 - val_accuracy: 0.9223\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 2.7447 - val_accuracy: 0.5356\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0479 - accuracy: 0.9896 - val_loss: 0.3969 - val_accuracy: 0.9199\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9880 - val_loss: 0.3374 - val_accuracy: 0.9312\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9877 - val_loss: 0.5757 - val_accuracy: 0.8956\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0537 - accuracy: 0.9875 - val_loss: 0.6117 - val_accuracy: 0.8940\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9872 - val_loss: 0.4914 - val_accuracy: 0.8932\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 0.9870 - val_loss: 0.2930 - val_accuracy: 0.9361\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9872 - val_loss: 0.5202 - val_accuracy: 0.8989\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0505 - accuracy: 0.9899 - val_loss: 0.9910 - val_accuracy: 0.6351\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0656 - accuracy: 0.9835 - val_loss: 1.6918 - val_accuracy: 0.5607\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9840 - val_loss: 5.2224 - val_accuracy: 0.5259\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9814 - val_loss: 0.6651 - val_accuracy: 0.8875\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9885 - val_loss: 0.3550 - val_accuracy: 0.9215\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.4050 - val_accuracy: 0.9094\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0604 - accuracy: 0.9846 - val_loss: 0.5566 - val_accuracy: 0.8770\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.6042 - val_accuracy: 0.8608\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9854 - val_loss: 0.4088 - val_accuracy: 0.9037\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9870 - val_loss: 0.7677 - val_accuracy: 0.8568\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9885 - val_loss: 0.3122 - val_accuracy: 0.9207\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9846 - val_loss: 0.9425 - val_accuracy: 0.8366\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9885 - val_loss: 2.0313 - val_accuracy: 0.7354\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9870 - val_loss: 2.5266 - val_accuracy: 0.5291\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.9880 - val_loss: 0.7800 - val_accuracy: 0.6456\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0489 - accuracy: 0.9901 - val_loss: 1.0541 - val_accuracy: 0.5761\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9885 - val_loss: 0.4263 - val_accuracy: 0.8989\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 0.9859 - val_loss: 0.9589 - val_accuracy: 0.8204\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0466 - accuracy: 0.9899 - val_loss: 2.9186 - val_accuracy: 0.7184\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 1.3575 - val_accuracy: 0.7799\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9909 - val_loss: 0.4748 - val_accuracy: 0.8948\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9904 - val_loss: 0.3838 - val_accuracy: 0.9126\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0502 - accuracy: 0.9899 - val_loss: 0.4073 - val_accuracy: 0.9053\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9846 - val_loss: 0.4439 - val_accuracy: 0.9175\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0569 - accuracy: 0.9859 - val_loss: 0.6264 - val_accuracy: 0.8592\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9854 - val_loss: 0.4085 - val_accuracy: 0.9239\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.6599 - val_accuracy: 0.8803\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9883 - val_loss: 0.8655 - val_accuracy: 0.8592\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 0.9896 - val_loss: 1.4583 - val_accuracy: 0.7791\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0483 - accuracy: 0.9899 - val_loss: 0.8802 - val_accuracy: 0.6311\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0527 - accuracy: 0.9899 - val_loss: 0.5278 - val_accuracy: 0.8964\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9877 - val_loss: 0.6109 - val_accuracy: 0.8972\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9840 - val_loss: 0.7445 - val_accuracy: 0.8641\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9846 - val_loss: 4.5470 - val_accuracy: 0.5291\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0586 - accuracy: 0.9848 - val_loss: 0.5476 - val_accuracy: 0.9078\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 0.9888 - val_loss: 0.4697 - val_accuracy: 0.9086\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9862 - val_loss: 1.1936 - val_accuracy: 0.5914\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9875 - val_loss: 0.6707 - val_accuracy: 0.6974\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 0.9862 - val_loss: 3.7029 - val_accuracy: 0.5275\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9877 - val_loss: 3.2471 - val_accuracy: 0.5251\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9899 - val_loss: 1.7974 - val_accuracy: 0.5461\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0501 - accuracy: 0.9885 - val_loss: 0.5218 - val_accuracy: 0.8714\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0554 - accuracy: 0.9888 - val_loss: 1.2465 - val_accuracy: 0.5914\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9885 - val_loss: 0.6231 - val_accuracy: 0.7290\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 0.9891 - val_loss: 0.6542 - val_accuracy: 0.8762\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0534 - accuracy: 0.9877 - val_loss: 0.2851 - val_accuracy: 0.9345\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0473 - accuracy: 0.9901 - val_loss: 0.5090 - val_accuracy: 0.8770\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9909 - val_loss: 0.5050 - val_accuracy: 0.8997\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0431 - accuracy: 0.9915 - val_loss: 0.3402 - val_accuracy: 0.9239\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9909 - val_loss: 0.3824 - val_accuracy: 0.9167\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9912 - val_loss: 0.2920 - val_accuracy: 0.9337\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9891 - val_loss: 0.9972 - val_accuracy: 0.8293\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 0.9867 - val_loss: 0.4598 - val_accuracy: 0.9118\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.9870 - val_loss: 0.8882 - val_accuracy: 0.8414\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9867 - val_loss: 0.3696 - val_accuracy: 0.9134\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9824 - val_loss: 1.0012 - val_accuracy: 0.8528\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 1.0218 - val_accuracy: 0.8277\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9846 - val_loss: 2.5017 - val_accuracy: 0.7176\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9862 - val_loss: 0.3060 - val_accuracy: 0.9345\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9880 - val_loss: 0.4037 - val_accuracy: 0.9126\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9883 - val_loss: 0.4563 - val_accuracy: 0.9159\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0537 - accuracy: 0.9891 - val_loss: 4.8935 - val_accuracy: 0.5259\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9867 - val_loss: 0.9649 - val_accuracy: 0.6206\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9830 - val_loss: 0.2666 - val_accuracy: 0.9401\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 0.5564 - val_accuracy: 0.9021\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9814 - val_loss: 0.5387 - val_accuracy: 0.9037\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9755 - val_loss: 0.2624 - val_accuracy: 0.9361\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0764 - accuracy: 0.9795 - val_loss: 0.7238 - val_accuracy: 0.8827\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0598 - accuracy: 0.9846 - val_loss: 1.9729 - val_accuracy: 0.7451\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9883 - val_loss: 2.5956 - val_accuracy: 0.7152\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9893 - val_loss: 1.7174 - val_accuracy: 0.7638\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9893 - val_loss: 1.6525 - val_accuracy: 0.7638\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9880 - val_loss: 0.5587 - val_accuracy: 0.8964\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0523 - accuracy: 0.9864 - val_loss: 2.3532 - val_accuracy: 0.7314\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9856 - val_loss: 1.9210 - val_accuracy: 0.7557\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0578 - accuracy: 0.9856 - val_loss: 1.5494 - val_accuracy: 0.7686\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9856 - val_loss: 1.7963 - val_accuracy: 0.7646\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9893 - val_loss: 2.4049 - val_accuracy: 0.7290\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9896 - val_loss: 1.2234 - val_accuracy: 0.7985\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9867 - val_loss: 1.1280 - val_accuracy: 0.8269\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9904 - val_loss: 0.9203 - val_accuracy: 0.8600\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9883 - val_loss: 0.8239 - val_accuracy: 0.8592\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9899 - val_loss: 0.8226 - val_accuracy: 0.8511\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9907 - val_loss: 1.1591 - val_accuracy: 0.7994\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9904 - val_loss: 0.5691 - val_accuracy: 0.9037\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0442 - accuracy: 0.9904 - val_loss: 0.9484 - val_accuracy: 0.8244\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0470 - accuracy: 0.9901 - val_loss: 0.3157 - val_accuracy: 0.9264\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9907 - val_loss: 0.3308 - val_accuracy: 0.9256\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9909 - val_loss: 0.5545 - val_accuracy: 0.8981\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9920 - val_loss: 0.5093 - val_accuracy: 0.9053\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0445 - accuracy: 0.9901 - val_loss: 1.1167 - val_accuracy: 0.6149\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9901 - val_loss: 0.4025 - val_accuracy: 0.9199\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9909 - val_loss: 0.4959 - val_accuracy: 0.9037\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 0.4992 - val_accuracy: 0.9053\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9920 - val_loss: 0.4044 - val_accuracy: 0.9183\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9915 - val_loss: 1.1915 - val_accuracy: 0.5850\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9901 - val_loss: 0.7929 - val_accuracy: 0.8439\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0521 - accuracy: 0.9885 - val_loss: 0.5070 - val_accuracy: 0.8883\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 0.2887 - val_accuracy: 0.9256\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9909 - val_loss: 0.3680 - val_accuracy: 0.9256\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9915 - val_loss: 0.6085 - val_accuracy: 0.8738\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9909 - val_loss: 1.3111 - val_accuracy: 0.5898\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 1.2217 - val_accuracy: 0.5987\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9901 - val_loss: 2.0311 - val_accuracy: 0.5566\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9909 - val_loss: 0.8133 - val_accuracy: 0.6489\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9923 - val_loss: 2.3304 - val_accuracy: 0.5502\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9901 - val_loss: 0.3761 - val_accuracy: 0.9207\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.9925 - val_loss: 0.5700 - val_accuracy: 0.7427\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9909 - val_loss: 0.3413 - val_accuracy: 0.9264\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0458 - accuracy: 0.9899 - val_loss: 0.7813 - val_accuracy: 0.7023\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9888 - val_loss: 0.5825 - val_accuracy: 0.8811\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 0.4794 - val_accuracy: 0.9045\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9888 - val_loss: 0.3673 - val_accuracy: 0.9239\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9915 - val_loss: 2.1248 - val_accuracy: 0.5591\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9917 - val_loss: 1.3714 - val_accuracy: 0.6084\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9915 - val_loss: 1.2908 - val_accuracy: 0.6092\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9904 - val_loss: 2.0594 - val_accuracy: 0.5526\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9920 - val_loss: 0.6646 - val_accuracy: 0.8617\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9912 - val_loss: 2.2679 - val_accuracy: 0.5429\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 0.9904 - val_loss: 1.2420 - val_accuracy: 0.8091\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9907 - val_loss: 0.3563 - val_accuracy: 0.9231\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.9851 - val_loss: 2.6255 - val_accuracy: 0.7290\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0566 - accuracy: 0.9856 - val_loss: 0.4995 - val_accuracy: 0.9070\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9872 - val_loss: 0.6125 - val_accuracy: 0.8851\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.9883 - val_loss: 1.6347 - val_accuracy: 0.7832\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0485 - accuracy: 0.9901 - val_loss: 2.7994 - val_accuracy: 0.4960\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9885 - val_loss: 1.1152 - val_accuracy: 0.8341\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0472 - accuracy: 0.9907 - val_loss: 1.9671 - val_accuracy: 0.5332\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9885 - val_loss: 0.5791 - val_accuracy: 0.8649\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9883 - val_loss: 3.6444 - val_accuracy: 0.5307\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 0.9891 - val_loss: 0.5495 - val_accuracy: 0.8932\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9896 - val_loss: 0.3099 - val_accuracy: 0.9296\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0463 - accuracy: 0.9896 - val_loss: 0.4697 - val_accuracy: 0.9183\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9901 - val_loss: 1.9745 - val_accuracy: 0.5631\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9867 - val_loss: 0.4634 - val_accuracy: 0.9142\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9867 - val_loss: 0.7133 - val_accuracy: 0.6837\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9875 - val_loss: 5.0333 - val_accuracy: 0.6982\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9883 - val_loss: 1.2913 - val_accuracy: 0.8204\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9848 - val_loss: 2.9672 - val_accuracy: 0.7144\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9854 - val_loss: 1.9595 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 0.9848 - val_loss: 1.8639 - val_accuracy: 0.7573\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9899 - val_loss: 1.6364 - val_accuracy: 0.7799\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9896 - val_loss: 0.3785 - val_accuracy: 0.9159\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0484 - accuracy: 0.9899 - val_loss: 1.0181 - val_accuracy: 0.8455\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9904 - val_loss: 1.0915 - val_accuracy: 0.5971\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9896 - val_loss: 0.6791 - val_accuracy: 0.8932\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9891 - val_loss: 0.4044 - val_accuracy: 0.9256\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9909 - val_loss: 0.5292 - val_accuracy: 0.8940\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9923 - val_loss: 0.4504 - val_accuracy: 0.9013\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 0.3564 - val_accuracy: 0.9110\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.2792 - val_accuracy: 0.9401\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 0.2923 - val_accuracy: 0.9345\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9907 - val_loss: 0.2926 - val_accuracy: 0.9312\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9904 - val_loss: 0.5523 - val_accuracy: 0.8932\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9909 - val_loss: 0.6695 - val_accuracy: 0.8900\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0445 - accuracy: 0.9899 - val_loss: 0.9008 - val_accuracy: 0.6254\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9907 - val_loss: 1.2089 - val_accuracy: 0.6028\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 0.3668 - val_accuracy: 0.9231\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9899 - val_loss: 0.3894 - val_accuracy: 0.9239\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 0.5754 - val_accuracy: 0.8940\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0439 - accuracy: 0.9899 - val_loss: 0.7460 - val_accuracy: 0.6837\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9880 - val_loss: 1.9361 - val_accuracy: 0.5566\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9872 - val_loss: 0.7071 - val_accuracy: 0.8859\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.9888 - val_loss: 0.3810 - val_accuracy: 0.9264\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0479 - accuracy: 0.9888 - val_loss: 0.4642 - val_accuracy: 0.9118\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9870 - val_loss: 0.4018 - val_accuracy: 0.9272\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9854 - val_loss: 0.3800 - val_accuracy: 0.9288\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0553 - accuracy: 0.9864 - val_loss: 2.5938 - val_accuracy: 0.5413\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9896 - val_loss: 0.4248 - val_accuracy: 0.9086\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9907 - val_loss: 1.4476 - val_accuracy: 0.5704\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 0.9893 - val_loss: 0.5202 - val_accuracy: 0.9061\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9909 - val_loss: 0.4024 - val_accuracy: 0.9207\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9893 - val_loss: 0.4285 - val_accuracy: 0.8997\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9907 - val_loss: 1.6841 - val_accuracy: 0.5518\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0450 - accuracy: 0.9899 - val_loss: 0.4103 - val_accuracy: 0.9110\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0435 - accuracy: 0.9915 - val_loss: 0.5689 - val_accuracy: 0.8859\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9923 - val_loss: 0.6601 - val_accuracy: 0.8900\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9925 - val_loss: 0.7944 - val_accuracy: 0.8617\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9920 - val_loss: 0.7072 - val_accuracy: 0.8657\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0423 - accuracy: 0.9917 - val_loss: 0.3792 - val_accuracy: 0.9191\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9901 - val_loss: 0.4276 - val_accuracy: 0.9037\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9891 - val_loss: 1.2481 - val_accuracy: 0.5866\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0498 - accuracy: 0.9872 - val_loss: 1.2285 - val_accuracy: 0.8196\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0515 - accuracy: 0.9883 - val_loss: 1.3321 - val_accuracy: 0.8269\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 2.5980 - val_accuracy: 0.7241\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9912 - val_loss: 0.6894 - val_accuracy: 0.8827\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9899 - val_loss: 1.8920 - val_accuracy: 0.7621\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9899 - val_loss: 0.4272 - val_accuracy: 0.9159\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9899 - val_loss: 0.4454 - val_accuracy: 0.9045\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0456 - accuracy: 0.9901 - val_loss: 0.4228 - val_accuracy: 0.9150\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0424 - accuracy: 0.9912 - val_loss: 1.5987 - val_accuracy: 0.5825\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9901 - val_loss: 1.6296 - val_accuracy: 0.7840\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0475 - accuracy: 0.9893 - val_loss: 0.6199 - val_accuracy: 0.8811\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9867 - val_loss: 0.8777 - val_accuracy: 0.6424\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0554 - accuracy: 0.9856 - val_loss: 2.8825 - val_accuracy: 0.5461\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9888 - val_loss: 8.9321 - val_accuracy: 0.5105\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.9838 - val_loss: 1.9933 - val_accuracy: 0.5348\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9824 - val_loss: 1.1710 - val_accuracy: 0.6367\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0665 - accuracy: 0.9835 - val_loss: 0.5139 - val_accuracy: 0.9239\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9862 - val_loss: 1.2233 - val_accuracy: 0.6084\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9870 - val_loss: 1.0266 - val_accuracy: 0.8463\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.9870 - val_loss: 2.5139 - val_accuracy: 0.5469\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9872 - val_loss: 0.8957 - val_accuracy: 0.8851\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.9824 - val_loss: 2.3680 - val_accuracy: 0.5340\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0745 - accuracy: 0.9811 - val_loss: 0.6417 - val_accuracy: 0.8989\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9896 - val_loss: 0.9294 - val_accuracy: 0.8584\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9891 - val_loss: 2.7752 - val_accuracy: 0.5186\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 0.9883 - val_loss: 2.5673 - val_accuracy: 0.5388\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0505 - accuracy: 0.9877 - val_loss: 0.3378 - val_accuracy: 0.9272\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9870 - val_loss: 0.3804 - val_accuracy: 0.9199\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9875 - val_loss: 0.6933 - val_accuracy: 0.8730\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0507 - accuracy: 0.9883 - val_loss: 0.5539 - val_accuracy: 0.9005\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9901 - val_loss: 0.7113 - val_accuracy: 0.8794\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9920 - val_loss: 0.3804 - val_accuracy: 0.9223\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9915 - val_loss: 0.5393 - val_accuracy: 0.9005\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9920 - val_loss: 0.6176 - val_accuracy: 0.8892\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9920 - val_loss: 1.0118 - val_accuracy: 0.8471\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9920 - val_loss: 0.6023 - val_accuracy: 0.8997\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9909 - val_loss: 0.8649 - val_accuracy: 0.8293\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 1.9727 - val_accuracy: 0.7500\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9917 - val_loss: 0.9277 - val_accuracy: 0.8358\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 1.6756 - val_accuracy: 0.7710\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9925 - val_loss: 0.3240 - val_accuracy: 0.9256\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9923 - val_loss: 1.4612 - val_accuracy: 0.7864\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0399 - accuracy: 0.9925 - val_loss: 0.3680 - val_accuracy: 0.9199\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 0.9920 - val_loss: 0.5134 - val_accuracy: 0.9013\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9928 - val_loss: 0.3667 - val_accuracy: 0.9215\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9917 - val_loss: 0.4566 - val_accuracy: 0.8997\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9899 - val_loss: 1.4321 - val_accuracy: 0.5874\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0460 - accuracy: 0.9891 - val_loss: 0.2880 - val_accuracy: 0.9401\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9912 - val_loss: 1.7581 - val_accuracy: 0.5752\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.5237 - val_accuracy: 0.9061\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0395 - accuracy: 0.9909 - val_loss: 0.4853 - val_accuracy: 0.9150\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9923 - val_loss: 0.3460 - val_accuracy: 0.9223\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9920 - val_loss: 0.3267 - val_accuracy: 0.9345\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 0.6444 - val_accuracy: 0.7338\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0418 - accuracy: 0.9915 - val_loss: 0.4869 - val_accuracy: 0.9159\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9917 - val_loss: 0.3467 - val_accuracy: 0.9320\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.3315 - val_accuracy: 0.9296\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0420 - accuracy: 0.9912 - val_loss: 0.4228 - val_accuracy: 0.9215\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0413 - accuracy: 0.9909 - val_loss: 0.8642 - val_accuracy: 0.8730\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 0.9017 - val_accuracy: 0.8633\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.7858 - val_accuracy: 0.8625\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9907 - val_loss: 1.7622 - val_accuracy: 0.5639\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9899 - val_loss: 0.4480 - val_accuracy: 0.9029\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9854 - val_loss: 0.6210 - val_accuracy: 0.9005\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.6624 - val_accuracy: 0.8827\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9856 - val_loss: 0.9147 - val_accuracy: 0.8673\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0475 - accuracy: 0.9885 - val_loss: 1.6066 - val_accuracy: 0.5777\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 0.9047 - val_accuracy: 0.8641\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9896 - val_loss: 0.8635 - val_accuracy: 0.8350\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9856 - val_loss: 0.7286 - val_accuracy: 0.8875\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9859 - val_loss: 3.1254 - val_accuracy: 0.5380\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 0.9872 - val_loss: 0.6810 - val_accuracy: 0.8900\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9843 - val_loss: 1.8154 - val_accuracy: 0.5599\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0565 - accuracy: 0.9846 - val_loss: 0.4105 - val_accuracy: 0.9223\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9870 - val_loss: 0.4140 - val_accuracy: 0.9118\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9843 - val_loss: 3.3958 - val_accuracy: 0.5299\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9846 - val_loss: 0.9331 - val_accuracy: 0.8584\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.9875 - val_loss: 1.0864 - val_accuracy: 0.6667\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.9888 - val_loss: 2.2358 - val_accuracy: 0.5324\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.7462 - val_accuracy: 0.8843\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 0.9891 - val_loss: 1.4613 - val_accuracy: 0.7937\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0507 - accuracy: 0.9875 - val_loss: 0.6116 - val_accuracy: 0.8883\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9840 - val_loss: 0.5886 - val_accuracy: 0.9013\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9840 - val_loss: 2.4123 - val_accuracy: 0.5380\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.9798 - val_loss: 0.8965 - val_accuracy: 0.8843\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9856 - val_loss: 0.6609 - val_accuracy: 0.8778\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9870 - val_loss: 0.8182 - val_accuracy: 0.8471\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9883 - val_loss: 0.9807 - val_accuracy: 0.8536\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9909 - val_loss: 0.6927 - val_accuracy: 0.8730\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9912 - val_loss: 0.5023 - val_accuracy: 0.9005\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0442 - accuracy: 0.9907 - val_loss: 0.5406 - val_accuracy: 0.8778\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 0.9899 - val_loss: 0.7490 - val_accuracy: 0.8738\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9893 - val_loss: 0.3493 - val_accuracy: 0.9296\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9901 - val_loss: 0.4222 - val_accuracy: 0.9159\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9901 - val_loss: 0.3514 - val_accuracy: 0.9328\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9901 - val_loss: 1.1157 - val_accuracy: 0.6068\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9920 - val_loss: 1.2189 - val_accuracy: 0.5930\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 0.3473 - val_accuracy: 0.9272\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9915 - val_loss: 0.3627 - val_accuracy: 0.9288\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 0.9917 - val_loss: 0.7861 - val_accuracy: 0.8673\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9901 - val_loss: 0.3389 - val_accuracy: 0.9272\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 0.9885 - val_loss: 0.8245 - val_accuracy: 0.6853\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0543 - accuracy: 0.9872 - val_loss: 0.5474 - val_accuracy: 0.8714\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0443 - accuracy: 0.9904 - val_loss: 0.6460 - val_accuracy: 0.8851\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9901 - val_loss: 0.4865 - val_accuracy: 0.9045\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 1.0300 - val_accuracy: 0.8471\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0403 - accuracy: 0.9907 - val_loss: 2.0991 - val_accuracy: 0.7476\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.5420 - val_accuracy: 0.9061\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9920 - val_loss: 0.5597 - val_accuracy: 0.9070\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 1.1587 - val_accuracy: 0.8390\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9917 - val_loss: 0.4139 - val_accuracy: 0.9304\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.8095 - val_accuracy: 0.8633\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9907 - val_loss: 0.5948 - val_accuracy: 0.8892\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9899 - val_loss: 0.5384 - val_accuracy: 0.9183\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.9885 - val_loss: 0.6127 - val_accuracy: 0.8964\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9909 - val_loss: 0.4433 - val_accuracy: 0.9159\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9888 - val_loss: 0.5593 - val_accuracy: 0.8916\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0464 - accuracy: 0.9875 - val_loss: 1.4386 - val_accuracy: 0.5858\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.5603 - val_accuracy: 0.9061\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0419 - accuracy: 0.9915 - val_loss: 0.4399 - val_accuracy: 0.9223\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9909 - val_loss: 1.5430 - val_accuracy: 0.5858\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.6516 - val_accuracy: 0.7306\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9917 - val_loss: 2.5332 - val_accuracy: 0.5502\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0458 - accuracy: 0.9912 - val_loss: 1.8825 - val_accuracy: 0.5858\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9928 - val_loss: 0.8008 - val_accuracy: 0.6691\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.9915 - val_loss: 0.7388 - val_accuracy: 0.6796\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0394 - accuracy: 0.9920 - val_loss: 0.7283 - val_accuracy: 0.6942\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9920 - val_loss: 0.3973 - val_accuracy: 0.9288\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0567 - accuracy: 0.9864 - val_loss: 0.4134 - val_accuracy: 0.9159\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9899 - val_loss: 0.4765 - val_accuracy: 0.9150\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9915 - val_loss: 0.3674 - val_accuracy: 0.9191\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.4405 - val_accuracy: 0.9126\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.9912 - val_loss: 0.8566 - val_accuracy: 0.8495\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9885 - val_loss: 0.6218 - val_accuracy: 0.8754\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0661 - accuracy: 0.9835 - val_loss: 0.8195 - val_accuracy: 0.8843\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9819 - val_loss: 1.3396 - val_accuracy: 0.8066\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 0.9816 - val_loss: 0.8609 - val_accuracy: 0.8754\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9854 - val_loss: 1.4365 - val_accuracy: 0.7840\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.3997 - val_accuracy: 0.9231\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9862 - val_loss: 0.9968 - val_accuracy: 0.8600\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 1.0475 - val_accuracy: 0.8277\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0544 - accuracy: 0.9885 - val_loss: 0.9863 - val_accuracy: 0.8366\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0501 - accuracy: 0.9864 - val_loss: 0.8743 - val_accuracy: 0.8511\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 0.9877 - val_loss: 0.5491 - val_accuracy: 0.8948\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9899 - val_loss: 0.6237 - val_accuracy: 0.8948\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9893 - val_loss: 1.2755 - val_accuracy: 0.5882\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0464 - accuracy: 0.9893 - val_loss: 0.9419 - val_accuracy: 0.8439\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 2.0156 - val_accuracy: 0.7532\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9904 - val_loss: 3.1769 - val_accuracy: 0.7193\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 1.3292 - val_accuracy: 0.8204\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0506 - accuracy: 0.9893 - val_loss: 2.2722 - val_accuracy: 0.7451\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0512 - accuracy: 0.9864 - val_loss: 3.8159 - val_accuracy: 0.7087\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9888 - val_loss: 1.1821 - val_accuracy: 0.8172\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0469 - accuracy: 0.9888 - val_loss: 3.9840 - val_accuracy: 0.7128\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9907 - val_loss: 0.7215 - val_accuracy: 0.8786\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9901 - val_loss: 1.0408 - val_accuracy: 0.8285\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9915 - val_loss: 0.9348 - val_accuracy: 0.8576\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0481 - accuracy: 0.9888 - val_loss: 0.8600 - val_accuracy: 0.8673\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0463 - accuracy: 0.9915 - val_loss: 0.8194 - val_accuracy: 0.8568\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 2.8792 - val_accuracy: 0.7184\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9909 - val_loss: 1.1678 - val_accuracy: 0.8236\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9925 - val_loss: 0.7018 - val_accuracy: 0.8859\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 0.9917 - val_loss: 0.6119 - val_accuracy: 0.8948\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0466 - accuracy: 0.9899 - val_loss: 0.4994 - val_accuracy: 0.9159\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9915 - val_loss: 0.4506 - val_accuracy: 0.9231\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0413 - accuracy: 0.9915 - val_loss: 0.5137 - val_accuracy: 0.9126\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9917 - val_loss: 0.3706 - val_accuracy: 0.9231\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9907 - val_loss: 1.0176 - val_accuracy: 0.8358\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.3831 - val_accuracy: 0.9175\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9904 - val_loss: 1.8478 - val_accuracy: 0.7824\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9923 - val_loss: 0.8581 - val_accuracy: 0.8641\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9925 - val_loss: 0.3897 - val_accuracy: 0.9215\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9923 - val_loss: 0.3887 - val_accuracy: 0.9215\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0387 - accuracy: 0.9920 - val_loss: 0.3325 - val_accuracy: 0.9248\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 1.4229 - val_accuracy: 0.6157\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 1.6900 - val_accuracy: 0.5979\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9920 - val_loss: 1.8020 - val_accuracy: 0.5914\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0361 - accuracy: 0.9928 - val_loss: 1.0317 - val_accuracy: 0.6408\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.9923 - val_loss: 1.6362 - val_accuracy: 0.5914\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.9928 - val_loss: 2.7889 - val_accuracy: 0.5574\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9917 - val_loss: 0.6918 - val_accuracy: 0.6974\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9931 - val_loss: 1.7411 - val_accuracy: 0.5939\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0391 - accuracy: 0.9915 - val_loss: 0.4393 - val_accuracy: 0.9094\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9925 - val_loss: 3.9694 - val_accuracy: 0.5413\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9915 - val_loss: 0.4046 - val_accuracy: 0.9207\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9909 - val_loss: 3.3139 - val_accuracy: 0.5413\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9893 - val_loss: 1.0185 - val_accuracy: 0.8430\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9915 - val_loss: 1.4561 - val_accuracy: 0.5777\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9899 - val_loss: 0.7028 - val_accuracy: 0.8956\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.7572 - val_accuracy: 0.8722\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0400 - accuracy: 0.9915 - val_loss: 0.4008 - val_accuracy: 0.9256\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9928 - val_loss: 0.4474 - val_accuracy: 0.9070\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9920 - val_loss: 0.3892 - val_accuracy: 0.9231\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0411 - accuracy: 0.9907 - val_loss: 0.4522 - val_accuracy: 0.9094\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 0.9899 - val_loss: 6.7161 - val_accuracy: 0.5299\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9899 - val_loss: 0.4635 - val_accuracy: 0.9215\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0481 - accuracy: 0.9896 - val_loss: 0.4974 - val_accuracy: 0.9175\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9901 - val_loss: 1.0804 - val_accuracy: 0.8447\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9917 - val_loss: 0.4695 - val_accuracy: 0.9239\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9923 - val_loss: 0.6641 - val_accuracy: 0.8900\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9928 - val_loss: 0.4279 - val_accuracy: 0.9215\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9907 - val_loss: 0.6370 - val_accuracy: 0.8972\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 0.5090 - val_accuracy: 0.9094\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.5218 - val_accuracy: 0.9061\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.8386 - val_accuracy: 0.8754\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9925 - val_loss: 0.7438 - val_accuracy: 0.8908\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9928 - val_loss: 0.7774 - val_accuracy: 0.7079\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 0.9925 - val_loss: 0.5705 - val_accuracy: 0.9053\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9917 - val_loss: 0.3754 - val_accuracy: 0.9256\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.4926 - val_accuracy: 0.9094\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9907 - val_loss: 0.7388 - val_accuracy: 0.6869\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9907 - val_loss: 0.5218 - val_accuracy: 0.8883\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0402 - accuracy: 0.9915 - val_loss: 1.5787 - val_accuracy: 0.5898\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 0.8001 - val_accuracy: 0.8875\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9925 - val_loss: 0.3873 - val_accuracy: 0.9223\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0391 - accuracy: 0.9920 - val_loss: 1.0087 - val_accuracy: 0.8560\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0383 - accuracy: 0.9925 - val_loss: 0.7278 - val_accuracy: 0.8908\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9920 - val_loss: 0.8851 - val_accuracy: 0.8665\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.8557 - val_accuracy: 0.8706\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9915 - val_loss: 1.5075 - val_accuracy: 0.7937\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0386 - accuracy: 0.9920 - val_loss: 0.4839 - val_accuracy: 0.9078\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9920 - val_loss: 0.3940 - val_accuracy: 0.9207\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0410 - accuracy: 0.9909 - val_loss: 0.2617 - val_accuracy: 0.9377\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0412 - accuracy: 0.9904 - val_loss: 2.1328 - val_accuracy: 0.7549\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0435 - accuracy: 0.9901 - val_loss: 0.5651 - val_accuracy: 0.8997\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9912 - val_loss: 0.6638 - val_accuracy: 0.7176\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9859 - val_loss: 0.4844 - val_accuracy: 0.9126\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9896 - val_loss: 4.1467 - val_accuracy: 0.5372\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9856 - val_loss: 0.7183 - val_accuracy: 0.8754\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 0.8552 - val_accuracy: 0.8722\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.7556 - val_accuracy: 0.8762\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9891 - val_loss: 1.2303 - val_accuracy: 0.6230\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9907 - val_loss: 4.5283 - val_accuracy: 0.5129\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9904 - val_loss: 1.7209 - val_accuracy: 0.5995\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 5.3690 - val_accuracy: 0.5210\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9909 - val_loss: 5.1340 - val_accuracy: 0.5307\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 0.9915 - val_loss: 2.6351 - val_accuracy: 0.5639\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9915 - val_loss: 3.1082 - val_accuracy: 0.5510\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.9901 - val_loss: 0.4440 - val_accuracy: 0.9159\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0432 - accuracy: 0.9907 - val_loss: 0.6404 - val_accuracy: 0.7306\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.4123 - val_accuracy: 0.9272\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.7556 - val_accuracy: 0.8706\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 1.1664 - val_accuracy: 0.8163\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9909 - val_loss: 2.2294 - val_accuracy: 0.7387\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.8304 - val_accuracy: 0.8641\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 0.9907 - val_loss: 1.3994 - val_accuracy: 0.7864\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 1.0168 - val_accuracy: 0.8382\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9885 - val_loss: 1.6964 - val_accuracy: 0.7735\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.5580 - val_accuracy: 0.9029\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0410 - accuracy: 0.9909 - val_loss: 1.1195 - val_accuracy: 0.8422\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0459 - accuracy: 0.9891 - val_loss: 0.4193 - val_accuracy: 0.9320\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 1.1248 - val_accuracy: 0.8633\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9893 - val_loss: 1.2228 - val_accuracy: 0.8406\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 1.1997 - val_accuracy: 0.8382\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9899 - val_loss: 0.4280 - val_accuracy: 0.9223\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9893 - val_loss: 0.7950 - val_accuracy: 0.8608\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0540 - accuracy: 0.9872 - val_loss: 0.7220 - val_accuracy: 0.8956\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0551 - accuracy: 0.9854 - val_loss: 2.6037 - val_accuracy: 0.5388\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.4646 - val_accuracy: 0.9142\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9909 - val_loss: 0.8174 - val_accuracy: 0.6950\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0438 - accuracy: 0.9883 - val_loss: 1.1463 - val_accuracy: 0.6278\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9901 - val_loss: 4.7217 - val_accuracy: 0.5316\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9888 - val_loss: 1.0264 - val_accuracy: 0.8422\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9909 - val_loss: 1.0364 - val_accuracy: 0.6489\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9920 - val_loss: 0.3390 - val_accuracy: 0.9207\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.3629 - val_accuracy: 0.9256\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0414 - accuracy: 0.9917 - val_loss: 0.7173 - val_accuracy: 0.8689\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 0.9883 - val_loss: 0.4610 - val_accuracy: 0.9045\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.9877 - val_loss: 0.7715 - val_accuracy: 0.8835\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0475 - accuracy: 0.9888 - val_loss: 0.6729 - val_accuracy: 0.8948\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.7635 - val_accuracy: 0.8859\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9920 - val_loss: 0.4738 - val_accuracy: 0.9061\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9925 - val_loss: 0.3733 - val_accuracy: 0.9248\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 0.9888 - val_loss: 0.4352 - val_accuracy: 0.9142\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0429 - accuracy: 0.9896 - val_loss: 1.9847 - val_accuracy: 0.5526\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9891 - val_loss: 0.5968 - val_accuracy: 0.8964\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9856 - val_loss: 2.9650 - val_accuracy: 0.5477\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9840 - val_loss: 0.7027 - val_accuracy: 0.6958\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9816 - val_loss: 3.3568 - val_accuracy: 0.5227\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9734 - val_loss: 0.4315 - val_accuracy: 0.9094\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0672 - accuracy: 0.9824 - val_loss: 1.6190 - val_accuracy: 0.7896\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9824 - val_loss: 0.8487 - val_accuracy: 0.8536\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9870 - val_loss: 0.6844 - val_accuracy: 0.8900\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 0.9854 - val_loss: 2.1864 - val_accuracy: 0.7565\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9856 - val_loss: 0.8151 - val_accuracy: 0.8827\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0561 - accuracy: 0.9867 - val_loss: 0.7139 - val_accuracy: 0.8964\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9838 - val_loss: 5.1630 - val_accuracy: 0.5405\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 0.9843 - val_loss: 2.3616 - val_accuracy: 0.7484\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0533 - accuracy: 0.9864 - val_loss: 1.2282 - val_accuracy: 0.6626\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.9893 - val_loss: 0.8856 - val_accuracy: 0.8592\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9915 - val_loss: 1.5283 - val_accuracy: 0.8010\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9928 - val_loss: 0.7336 - val_accuracy: 0.8908\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9915 - val_loss: 0.4495 - val_accuracy: 0.9231\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9920 - val_loss: 0.4648 - val_accuracy: 0.9207\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9920 - val_loss: 0.4668 - val_accuracy: 0.9159\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9928 - val_loss: 0.5101 - val_accuracy: 0.9126\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0390 - accuracy: 0.9925 - val_loss: 0.4840 - val_accuracy: 0.9159\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 0.5386 - val_accuracy: 0.9053\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0407 - accuracy: 0.9920 - val_loss: 0.7344 - val_accuracy: 0.8794\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9925 - val_loss: 1.0288 - val_accuracy: 0.8414\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9923 - val_loss: 1.0875 - val_accuracy: 0.8277\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.4736 - val_accuracy: 0.9167\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.4502 - val_accuracy: 0.9215\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.6718 - val_accuracy: 0.8981\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0410 - accuracy: 0.9907 - val_loss: 0.3475 - val_accuracy: 0.9320\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0470 - accuracy: 0.9891 - val_loss: 0.4278 - val_accuracy: 0.9199\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9904 - val_loss: 0.5059 - val_accuracy: 0.9110\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.9920 - val_loss: 0.4327 - val_accuracy: 0.9215\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.5091 - val_accuracy: 0.9126\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9915 - val_loss: 0.7757 - val_accuracy: 0.8697\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0406 - accuracy: 0.9917 - val_loss: 0.6539 - val_accuracy: 0.8851\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9859 - val_loss: 0.3881 - val_accuracy: 0.9191\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0492 - accuracy: 0.9870 - val_loss: 2.1279 - val_accuracy: 0.7565\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9885 - val_loss: 1.7930 - val_accuracy: 0.7824\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0460 - accuracy: 0.9896 - val_loss: 3.3757 - val_accuracy: 0.6610\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0437 - accuracy: 0.9904 - val_loss: 1.2389 - val_accuracy: 0.8107\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.6008 - val_accuracy: 0.8883\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9893 - val_loss: 0.4570 - val_accuracy: 0.9118\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.5833 - val_accuracy: 0.8778\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0453 - accuracy: 0.9896 - val_loss: 0.6150 - val_accuracy: 0.8956\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0510 - accuracy: 0.9870 - val_loss: 4.2814 - val_accuracy: 0.5364\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0482 - accuracy: 0.9885 - val_loss: 3.1696 - val_accuracy: 0.5566\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9899 - val_loss: 4.8569 - val_accuracy: 0.5413\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9904 - val_loss: 0.8302 - val_accuracy: 0.6602\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9862 - val_loss: 0.8817 - val_accuracy: 0.8681\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 0.6143 - val_accuracy: 0.9045\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9899 - val_loss: 0.5377 - val_accuracy: 0.9110\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
    "outputId": "4354cc75-e44d-4d2a-ac4b-c55a4b3a9305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1fac08cb90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
    "outputId": "97e18fb9-4340-478c-e307-82c03282e9cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][10:])\n",
    "plt.plot(history.history['val_loss'][10:])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a964a60-488a-431e-8bcc-586e90d8956b",
   "metadata": {
    "id": "8a964a60-488a-431e-8bcc-586e90d8956b"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7C0QyTLHO8q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7C0QyTLHO8q",
    "outputId": "78587010-2aa8-4cc7-e82f-7c40e11ce705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3737922e-08, 1.0016398e-11, 9.9999988e-01],\n",
       "       [9.9987245e-01, 2.7409882e-05, 1.0007939e-04],\n",
       "       [9.5023328e-01, 4.0405195e-02, 9.3614869e-03],\n",
       "       ...,\n",
       "       [9.8611218e-01, 1.0450194e-02, 3.4375903e-03],\n",
       "       [1.0585216e-04, 3.0708690e-15, 9.9989414e-01],\n",
       "       [9.6254772e-01, 2.2802712e-02, 1.4649530e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d3ecc-9cf4-4b1b-a1f8-7394eae20128",
   "metadata": {
    "id": "1c8d3ecc-9cf4-4b1b-a1f8-7394eae20128"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ljWvGo9skgS",
   "metadata": {
    "id": "1ljWvGo9skgS"
   },
   "outputs": [],
   "source": [
    "y_pred= np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIninuG_Hixu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIninuG_Hixu",
    "outputId": "8d52a3ce-46d5-41c3-f339-ec8e2feee684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NzoyhrD4tO9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NzoyhrD4tO9",
    "outputId": "da09ab77-c439-431e-82a8-93fc98f20b49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57",
   "metadata": {
    "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_test': y_test.ravel().astype(int).tolist(),\n",
    "    'y_pred': y_pred.ravel().astype(int).tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
    "outputId": "aa49cb9d-c88e-437b-9a31-2809577d1da1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5a9d1807-157f-450c-90f3-9277324fad7c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>292</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a9d1807-157f-450c-90f3-9277324fad7c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5a9d1807-157f-450c-90f3-9277324fad7c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5a9d1807-157f-450c-90f3-9277324fad7c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "y_pred    0    1    2\n",
       "y_test               \n",
       "0       495   35    2\n",
       "1         2  292   58\n",
       "2         1   12  339"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df['y_test'], df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f",
   "metadata": {
    "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "__GCNJUQzHny",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__GCNJUQzHny",
    "outputId": "0b819a16-2d58-4435-927f-343a75565ae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.01,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c451d57-513f-476a-acbf-5b5a58a90437",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "8c451d57-513f-476a-acbf-5b5a58a90437",
    "outputId": "c8edd43e-3d45-432e-c46d-f23b5f9e9cdd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8e388d899b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m        \u001b[0;34m[\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.08\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m        [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08]]])))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 9, 6), found shape=(None, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "np.argmax(model.predict(np.array([[[0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08],\n",
    "       [0.08,  0.08,  0.08,  0.08, -0.08, -0.08, -0.08,  0.08]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758a797-ce91-4c86-b48f-11b7906e3f1c",
   "metadata": {
    "id": "e758a797-ce91-4c86-b48f-11b7906e3f1c"
   },
   "outputs": [],
   "source": [
    "x_new = X_test[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028ea89-c194-4257-b879-9c5125aa092c",
   "metadata": {
    "id": "e028ea89-c194-4257-b879-9c5125aa092c"
   },
   "outputs": [],
   "source": [
    "argmax(model.predict(np.array([[[-0.04,  0.69,  0.72,  0.07, -0.19, -0.63, -0.71,  0.23],\n",
    "       [-0.13,  0.69,  0.7 ,  0.14, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.22,  0.67,  0.67,  0.23, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.25,  0.67,  0.65,  0.25, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.31,  0.65,  0.63,  0.3 , -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.35,  0.63,  0.6 ,  0.34, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.34,  0.64,  0.61,  0.33, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.34,  0.64,  0.61,  0.33, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.24,  0.67,  0.66,  0.25, -0.19, -0.64, -0.71,  0.23],\n",
    "       [-0.12,  0.69,  0.7 ,  0.14, -0.19, -0.64, -0.71,  0.23]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeab939-e224-45cb-aeac-cba492ce706e",
   "metadata": {
    "id": "caeab939-e224-45cb-aeac-cba492ce706e"
   },
   "outputs": [],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd53482-ba40-4e2e-91e4-86a77c1bd571",
   "metadata": {
    "id": "1cd53482-ba40-4e2e-91e4-86a77c1bd571"
   },
   "outputs": [],
   "source": [
    "(1,) + x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe40741-ef5e-4586-8099-7ea3940df013",
   "metadata": {
    "id": "ffe40741-ef5e-4586-8099-7ea3940df013"
   },
   "outputs": [],
   "source": [
    "X_new = x_new.reshape((1,) + x_new.shape)\n",
    "fast_or_slow = saved_model(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc15ee-ec14-4cbf-a2d2-bf0d17176afa",
   "metadata": {
    "id": "a4dc15ee-ec14-4cbf-a2d2-bf0d17176afa"
   },
   "outputs": [],
   "source": [
    "float(fast_or_slow[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54844c3c-4be3-4599-8327-c2cfa0751e0e",
   "metadata": {
    "id": "54844c3c-4be3-4599-8327-c2cfa0751e0e"
   },
   "outputs": [],
   "source": [
    "print(X_new.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7rw6-XGxwHZw",
   "metadata": {
    "id": "7rw6-XGxwHZw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZD1w6TZwk0e",
   "metadata": {
    "id": "vZD1w6TZwk0e"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dg1rDKBsw7S3",
   "metadata": {
    "id": "Dg1rDKBsw7S3"
   },
   "outputs": [],
   "source": [
    "np.fromstring(X_new.tobytes(), dtype=float).reshape(1,10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DlzAFGAuxUHF",
   "metadata": {
    "id": "DlzAFGAuxUHF"
   },
   "outputs": [],
   "source": [
    "comma_string = \"[[[-1.402271e-03 -2.203955e-08 7.028995e-07 9.999990e-01 -2.328306e-10 -6.455648e-09 7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00]]])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xywYtiQuDssb",
   "metadata": {
    "id": "xywYtiQuDssb"
   },
   "outputs": [],
   "source": [
    "spaces_string = comma_string.replace(' ', ',')\n",
    "spaces_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XDNr41Vm7MsD",
   "metadata": {
    "id": "XDNr41Vm7MsD"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "input = np.array([[[0.08, 0.14, 0.09, 0.18],\n",
    "       [0.08, 0.14, 0.09, 0.22],\n",
    "       [0.08, 0.14, 0.08, 0.17],\n",
    "       [0.08, 0.14, 0.08, 0.1 ],\n",
    "       [0.08, 0.14, 0.07, 0.08],\n",
    "       [0.08, 0.14, 0.07, 0.08],\n",
    "       [0.09, 0.2 , 0.07, 0.08],\n",
    "       [0.1 , 0.32, 0.07, 0.07],\n",
    "       [0.1 , 0.29, 0.07, 0.07],\n",
    "       [0.09, 0.24, 0.07, 0.07]]])\n",
    "    \n",
    "lista_string=\"[0.08, 0.14, 0.09, 0.18]\"\n",
    "lista= ast.literal_eval(lista_string)\n",
    "input = np.insert(input[0], 0,lista).reshape(1,11,4)\n",
    "input = input[:,:-1,:]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y9SXyZnkxVs1",
   "metadata": {
    "id": "Y9SXyZnkxVs1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dYZo4dM_E7y8",
   "metadata": {
    "id": "dYZo4dM_E7y8"
   },
   "outputs": [],
   "source": [
    "/content/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F2L9U_219JYL",
   "metadata": {
    "id": "F2L9U_219JYL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I6lCTiBu9hIN",
   "metadata": {
    "id": "I6lCTiBu9hIN"
   },
   "outputs": [],
   "source": [
    "!zip -r model.zip model/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "txtVW0lZk0i2",
   "metadata": {
    "id": "txtVW0lZk0i2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmP1iwCVrCWB",
   "metadata": {
    "id": "jmP1iwCVrCWB"
   },
   "outputs": [],
   "source": [
    "print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xnhM2JtlrKUG",
   "metadata": {
    "id": "xnhM2JtlrKUG"
   },
   "outputs": [],
   "source": [
    "input = np.array([[[ 2.66, -1.94,  0.66, -0.07],\n",
    "       [ 2.66, -1.94,  0.66, -0.07],\n",
    "       [ 2.65, -2.1 ,  0.66, -0.07],\n",
    "       [ 2.65, -2.2 ,  0.66, -0.07],\n",
    "       [ 2.65, -2.22,  0.66, -0.07],\n",
    "       [ 2.65, -2.22,  0.68,  0.01],\n",
    "       [ 2.64, -2.22,  0.68,  0.18],\n",
    "       [ 2.64, -2.22,  0.69,  0.26],\n",
    "       [ 2.64, -2.22,  0.67,  0.16],\n",
    "       [ 2.64, -2.22,  0.67,  0.03]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-RaeJ9fealdj",
   "metadata": {
    "id": "-RaeJ9fealdj"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "lista_string=\"[ 2.66, -1.94,  0.66, -0.07]\"\n",
    "lista= ast.literal_eval(lista_string)\n",
    "input = np.append(input[0],[lista],axis=0).reshape(1,11,4)\n",
    "input = input[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSPIJMHBapbY",
   "metadata": {
    "id": "dSPIJMHBapbY"
   },
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8LVg3UYja8xp",
   "metadata": {
    "id": "8LVg3UYja8xp"
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I3PN3mu1iAis",
   "metadata": {
    "id": "I3PN3mu1iAis"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "s = \"[[[-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00] [-1.402271e-03 -2.203955e-08  7.028995e-07  9.999990e-01 -2.328306e-10 -6.455648e-09  7.037297e-07  1.000000e+00]]]\"\n",
    "\n",
    "def add_comma(match):\n",
    "    return match.group(0) + ','\n",
    "\n",
    "s = re.sub(r'\\[[0-9\\.\\s]+\\]', add_comma, s)\n",
    "s = re.sub(r'([0-9\\.]+)', add_comma, s)\n",
    "mylist = eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sVQuC3TvzIGz",
   "metadata": {
    "id": "sVQuC3TvzIGz"
   },
   "outputs": [],
   "source": [
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WaxWOPL_zKMZ",
   "metadata": {
    "id": "WaxWOPL_zKMZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
