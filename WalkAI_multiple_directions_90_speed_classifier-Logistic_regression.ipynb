{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2",
   "metadata": {
    "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandokenjisakabe/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from numpy.random import default_rng\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1",
   "metadata": {
    "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline params.\n",
    "DATA_PATH = Path('data/')\n",
    "FILENAME_STOP = 'stop_90_diff_quat.csv'\n",
    "FILENAME_0 = '0_90_diff_quat.csv'\n",
    "FILENAME_90 = '90_90_diff_quat.csv'\n",
    "FILENAME_180 = '180_90_diff_quat.csv'\n",
    "FILENAME_270 = '270_90_diff_quat.csv'\n",
    "\n",
    "# # Loading pipeline params.\n",
    "# DATA_PATH = Path('data')\n",
    "# FILENAME_STOP = 'stop.csv'\n",
    "# FILENAME_0 = 'm_0.csv'\n",
    "# FILENAME_90 = 'm_90.csv'\n",
    "# FILENAME_180 = 'm_180.csv'\n",
    "# FILENAME_270 = 'm_270.csv'\n",
    "\n",
    "\n",
    "NUM_TIMESTEPS = 6\n",
    "IGNORE_FRACTION = 0.1\n",
    "TEST_FRACTION = 0.25\n",
    "VALIDATION_FRACTION = 0.25\n",
    "\n",
    "\n",
    "# Training params.\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a045adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    num_timesteps,\n",
    "    ignore_fraction,\n",
    "    test_fraction,\n",
    "):\n",
    "\n",
    "    def read_and_prepare_data(\n",
    "        path,\n",
    "        class_,\n",
    "        num_timesteps,\n",
    "        ignore_fraction,\n",
    "        test_fraction,\n",
    "    ):\n",
    "\n",
    "        def split_temporally(X, test_fraction):\n",
    "            num_samples = X.shape[0]\n",
    "            num_train = int(num_samples * (1.0 - test_fraction))\n",
    "            X_train, X_test = X[:num_train], X[num_train:]\n",
    "            return X_train, X_test\n",
    "\n",
    "        def transform_into_sequences(X, num_timesteps):\n",
    "            num_samples = X.shape[0]\n",
    "            X_seq = []\n",
    "            for k in range(num_samples - num_timesteps + 1):\n",
    "                X_seq.append(X[k:(k + num_timesteps)])\n",
    "            X_seq = np.array(X_seq)\n",
    "            y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "            return X_seq, y_seq\n",
    "\n",
    "        X = pd.read_csv(path).values\n",
    "        X = X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "\n",
    "        # Ignore beginning and end.\n",
    "        num_samples = X.shape[0]\n",
    "        num_ignore = int(ignore_fraction * num_samples)\n",
    "        X = X[num_ignore:-num_ignore]\n",
    "\n",
    "        # Split X temporally.\n",
    "        X_train, X_test = split_temporally(X, test_fraction)\n",
    "        \n",
    "        # Transform X into short sequences.\n",
    "        X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "        X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "    def shuffle_data(X, y):\n",
    "        idx = np.arange(len(X))\n",
    "        default_rng().shuffle(idx)\n",
    "        X_shuffled = X[idx, :]\n",
    "        y_shuffled = y[idx]\n",
    "        return X_shuffled, y_shuffled\n",
    "\n",
    "    X_train_stop, y_train_stop, X_test_stop, y_test_stop, X_val_stop, y_val_stop = \\\n",
    "        read_and_prepare_data(\n",
    "            path_stop,\n",
    "            0.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_0, y_train_0, X_test_0, y_test_0, X_val_0, y_val_0 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_0,\n",
    "            1.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train_90, y_train_90, X_test_90, y_test_90, X_val_90, y_val_90 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_90,\n",
    "            2.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_180, y_train_180, X_test_180, y_test_180, X_val_180, y_val_180 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_180,\n",
    "            3.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_270, y_train_270, X_test_270, y_test_270,X_val_270, y_val_270  = \\\n",
    "        read_and_prepare_data(\n",
    "            path_270,\n",
    "            4.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train = np.concatenate((X_train_stop, X_train_0, X_train_90, X_train_180, X_train_270), axis=0)\n",
    "    y_train = np.concatenate((y_train_stop, y_train_0, y_train_90, y_train_180, y_train_270), axis=0)\n",
    "    X_test = np.concatenate((X_test_stop, X_test_0, X_test_90, X_test_180, X_test_270), axis=0)\n",
    "    y_test = np.concatenate((y_test_stop, y_test_0, y_test_90, y_test_180, y_test_270), axis=0)\n",
    "    X_val = np.concatenate((X_val_stop, X_val_0, X_val_90, X_val_180, X_val_270), axis=0)\n",
    "    y_val = np.concatenate((y_val_stop, y_val_0, y_val_90, y_val_180, y_val_270), axis=0)\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train, y_train = shuffle_data(X_train, y_train)\n",
    "    X_test, y_test = shuffle_data(X_test, y_test)\n",
    "    X_val, y_val = shuffle_data(X_val, y_val)\n",
    "    return X_train, X_test,X_val, y_train, y_test, y_val\n",
    "\n",
    "\n",
    "path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "path_0 = Path(DATA_PATH, FILENAME_0)\n",
    "path_90 = Path(DATA_PATH, FILENAME_90)\n",
    "path_180 = Path(DATA_PATH, FILENAME_180)\n",
    "path_270 = Path(DATA_PATH, FILENAME_270)\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test , y_val= load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    NUM_TIMESTEPS,\n",
    "    IGNORE_FRACTION,\n",
    "    TEST_FRACTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f52716d-1339-4484-9fd3-d5206979ba8e",
   "metadata": {
    "id": "7f52716d-1339-4484-9fd3-d5206979ba8e"
   },
   "outputs": [],
   "source": [
    "# def load_data(\n",
    "#     path_stop,\n",
    "#     path_0,\n",
    "#     path_90,\n",
    "#     path_180,\n",
    "#     path_270,\n",
    "#     num_timesteps,\n",
    "#     ignore_fraction,\n",
    "#     test_fraction,\n",
    "# ):\n",
    "\n",
    "#     def read_and_prepare_data(\n",
    "#         path,\n",
    "#         class_,\n",
    "#         num_timesteps,\n",
    "#         ignore_fraction,\n",
    "#         test_fraction,\n",
    "#     ):\n",
    "\n",
    "#         def split_temporally(X, test_fraction):\n",
    "#             num_samples = X.shape[0]\n",
    "#             num_train = int(num_samples * (1.0 - test_fraction))\n",
    "#             X_train, X_test = X[:num_train], X[num_train:]\n",
    "#             return X_train, X_test\n",
    "\n",
    "#         def transform_into_sequences(X, num_timesteps):\n",
    "#             num_samples = X.shape[0]\n",
    "#             X_seq = []\n",
    "#             for k in range(num_samples - num_timesteps + 1):\n",
    "#                 X_seq.append(X[k:(k + num_timesteps)])\n",
    "#             X_seq = np.array(X_seq)\n",
    "#             y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "#             return X_seq, y_seq\n",
    "\n",
    "#         X = pd.read_csv(path).values\n",
    "#         X = X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "\n",
    "#         # Ignore beginning and end.\n",
    "#         num_samples = X.shape[0]\n",
    "#         num_ignore = int(ignore_fraction * num_samples)\n",
    "#         X = X[num_ignore:-num_ignore]\n",
    "\n",
    "#         # Split X temporally.\n",
    "#         X_train, X_test = split_temporally(X, test_fraction)\n",
    "\n",
    "#         # Transform X into short sequences.\n",
    "#         X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "#         X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "\n",
    "#         return X_train, y_train, X_test, y_test\n",
    "\n",
    "#     def shuffle_data(X, y):\n",
    "#         idx = np.arange(len(X))\n",
    "#         default_rng().shuffle(idx)\n",
    "#         X_shuffled = X[idx, :]\n",
    "#         y_shuffled = y[idx]\n",
    "#         return X_shuffled, y_shuffled\n",
    "\n",
    "#     X_train_stop, y_train_stop, X_test_stop, y_test_stop = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_stop,\n",
    "#             0.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_0, y_train_0, X_test_0, y_test_0 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_0,\n",
    "#             1.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "\n",
    "#     X_train_90, y_train_90, X_test_90, y_test_90 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_90,\n",
    "#             2.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_180, y_train_180, X_test_180, y_test_180 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_180,\n",
    "#             3.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_270, y_train_270, X_test_270, y_test_270 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_270,\n",
    "#             4.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "\n",
    "#     X_train = np.concatenate((X_train_stop, X_train_0, X_train_90, X_train_180, X_train_270), axis=0)\n",
    "#     y_train = np.concatenate((y_train_stop, y_train_0, y_train_90, y_train_180, y_train_270), axis=0)\n",
    "#     X_test = np.concatenate((X_test_stop, X_test_0, X_test_90, X_test_180, X_test_270), axis=0)\n",
    "#     y_test = np.concatenate((y_test_stop, y_test_0, y_test_90, y_test_180, y_test_270), axis=0)\n",
    "\n",
    "#     X_train, y_train = shuffle_data(X_train, y_train)\n",
    "#     X_test, y_test = shuffle_data(X_test, y_test)\n",
    "\n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "# path_0 = Path(DATA_PATH, FILENAME_0)\n",
    "# path_90 = Path(DATA_PATH, FILENAME_90)\n",
    "# path_180 = Path(DATA_PATH, FILENAME_180)\n",
    "# path_270 = Path(DATA_PATH, FILENAME_270)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = load_data(\n",
    "#     path_stop,\n",
    "#     path_0,\n",
    "#     path_90,\n",
    "#     path_180,\n",
    "#     path_270,\n",
    "#     NUM_TIMESTEPS,\n",
    "#     IGNORE_FRACTION,\n",
    "#     TEST_FRACTION,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c35712-1089-44f3-89ef-ed471b144c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99c35712-1089-44f3-89ef-ed471b144c96",
    "outputId": "9076061a-8661-4d2e-c1ed-887a92ec640b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7175, 6, 14), (7175, 1), (1185, 6, 14), (1185, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "VqSuqgBCB_nA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqSuqgBCB_nA",
    "outputId": "26d50bbe-3fd3-4bed-e70e-7003d289c5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dye8vjENBtXX",
   "metadata": {
    "id": "dye8vjENBtXX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "-3TttkaRCM4l",
   "metadata": {
    "id": "-3TttkaRCM4l"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# CNN = Sequential(name=\"Sequential_CNN\")\n",
    "\n",
    "# CNN.add(Conv2D(256, kernel_size=(3, 3),\n",
    "#                strides=(2, 2), padding=\"same\",\n",
    "#                activation=\"selu\", input_shape=[6, 14, 1]))\n",
    "\n",
    "# CNN.add(MaxPooling2D(pool_size=(1, 1), strides=(1, 1),\n",
    "#                      padding=\"valid\"))\n",
    "\n",
    "# # # Add another pair of Conv2D and MaxPooling2D for more model depth,\n",
    "# # # followed by the flatten and multiple dense layers\n",
    "\n",
    "# # CNN.add(Conv2D(64, kernel_size=(3, 3),\n",
    "# #                strides=(2, 2), padding=\"same\",\n",
    "# #                activation=\"selu\"))\n",
    "\n",
    "# # CNN.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),\n",
    "# #                      padding=\"valid\"))\n",
    "\n",
    "# CNN.add(Flatten())\n",
    "\n",
    "# CNN.add(Dense(64, activation='selu'))\n",
    "# CNN.add(Dense(32, activation='selu'))\n",
    "# CNN.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a85634b-4e9c-45b8-b456-cb970457302f",
   "metadata": {
    "id": "3a85634b-4e9c-45b8-b456-cb970457302f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# CNN = Sequential(name=\"Sequential_CNN\")\n",
    "\n",
    "# CNN.add(Conv2D(256, kernel_size=(3, 3),\n",
    "#                strides=(1, 1), padding=\"same\",\n",
    "#                activation=\"selu\", input_shape=[6, 14, 1]))\n",
    "\n",
    "# CNN.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
    "#                      padding=\"valid\"))\n",
    "\n",
    "# # Add another pair of Conv2D and MaxPooling2D for more model depth,\n",
    "# # followed by the flatten and multiple dense layers\n",
    "\n",
    "# # CNN.add(Conv2D(64, kernel_size=(3, 3),\n",
    "# #                strides=(1, 1), padding=\"same\",\n",
    "# #                activation=\"selu\"))\n",
    "\n",
    "# # CNN.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),\n",
    "# #                      padding=\"valid\"))\n",
    "\n",
    "# CNN.add(Flatten())\n",
    "\n",
    "# CNN.add(Dense(64, activation='selu'))\n",
    "# CNN.add(Dense(32, activation='selu'))\n",
    "# CNN.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdca018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 14, 256)        2560      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 13, 256)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16640)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                166410    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,970\n",
      "Trainable params: 168,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 14:49:56.071943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(256, kernel_size=(3, 3),\n",
    "               strides=(1, 1), padding=\"same\",\n",
    "               activation=\"selu\", input_shape=[6, 14, 1]),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1),\n",
    "                     padding=\"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "j0C2RSxICKzq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0C2RSxICKzq",
    "outputId": "af853522-fdf6-40e4-8d0e-cd2a6dcdab9b"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics = ['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "911581af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "where_are_NaNsx = isnan(X_train)\n",
    "X_train[where_are_NaNsx] = 0\n",
    "\n",
    "where_are_NaNsy = isnan(y_train)\n",
    "y_train[where_are_NaNsy] = 0\n",
    "\n",
    "where_are_NaNsxt = isnan(X_test)\n",
    "X_test[where_are_NaNsxt] = 0\n",
    "\n",
    "where_are_NaNsyt = isnan(y_test)\n",
    "y_test[where_are_NaNsyt] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7baf8970-5318-4461-b828-d34c232afa5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7baf8970-5318-4461-b828-d34c232afa5f",
    "outputId": "08a66cc8-aeee-42ba-f039-9dfa2ba6f99e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# CNN.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer=optimizer,\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "# history = CNN.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=15,\n",
    "#     batch_size=256,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     verbose=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
    "outputId": "7211ef5c-5b4a-4afb-ad4f-7341eeb8f0f8"
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "# _, num_time, num_feat = X_train.shape\n",
    "\n",
    "# activation = 'selu'\n",
    "\n",
    "# DefaultConv1D = partial(\n",
    "#     keras.layers.Conv1D,\n",
    "#     kernel_size=1,\n",
    "#     activation=activation,\n",
    "#     padding=\"valid\",\n",
    "# )\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     DefaultConv1D(4 * num_feat, kernel_size=2, input_shape=[num_time, num_feat]),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     DefaultConv1D(num_feat, kernel_size=2),\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(num_time * num_feat, activation=activation),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(num_feat, activation=activation),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(5, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# model.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer=optimizer,\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     verbose=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc2d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # define the input shape\n",
    "# input_shape = (6, 14)\n",
    "\n",
    "# # create the input placeholder for the model\n",
    "# input_data = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# # reshape input data\n",
    "# input_data_reshaped = tf.keras.layers.Reshape((6, 14, 1))(input_data)\n",
    "\n",
    "# # define the convolutional layer\n",
    "# conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_data_reshaped)\n",
    "\n",
    "# # add maxpooling layer\n",
    "# maxpooling = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
    "\n",
    "\n",
    "# reshaped = tf.keras.layers.Reshape((2, 6*32))(maxpooling)\n",
    "\n",
    "# # define the recurrent layer\n",
    "# rnn = tf.keras.layers.GRU(units=64, return_sequences=True)(reshaped)\n",
    "\n",
    "# # add flatten layer\n",
    "# flatten = tf.keras.layers.Flatten()(rnn)\n",
    "\n",
    "# # define the fully connected layers\n",
    "# fc1 = tf.keras.layers.Dense(units=64, activation='relu')(flatten)\n",
    "# fc2 = tf.keras.layers.Dense(units=5, activation='softmax')(fc1)\n",
    "\n",
    "# # define the model\n",
    "# model = tf.keras.Model(inputs=input_data, outputs=fc2)\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f075d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113/113 [==============================] - 4s 28ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.8304 - val_sparse_categorical_accuracy: 0.7420\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 3s 25ms/step - loss: 0.3095 - sparse_categorical_accuracy: 0.8754 - val_loss: 0.7439 - val_sparse_categorical_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 3s 25ms/step - loss: 0.1872 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.7222 - val_sparse_categorical_accuracy: 0.9403\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 0.1187 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.8251 - val_sparse_categorical_accuracy: 0.9109\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 3s 29ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.8500 - val_sparse_categorical_accuracy: 0.9429\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.8255 - val_sparse_categorical_accuracy: 0.9420\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 3s 25ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.8946 - val_sparse_categorical_accuracy: 0.9387\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.8589 - val_sparse_categorical_accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 3s 30ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.8977 - val_sparse_categorical_accuracy: 0.9437\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 3s 30ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.9683 - val_sparse_categorical_accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb38ca03a60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
    "outputId": "4354cc75-e44d-4d2a-ac4b-c55a4b3a9305"
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c0564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history_2.history['sparse_categorical_accuracy'])\n",
    "# plt.plot(history_2.history['val_sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40247d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history_2.history['accuracy'])\n",
    "# plt.plot(history_2.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5841334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
    "outputId": "97e18fb9-4340-478c-e307-82c03282e9cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKGklEQVR4nO3dX4hm913H8c/XxIB/yrR0V5FNy6ZSY/fCYl1rEZWqFyaBGNReNBULJbgUqXjZ6oVeeKN3IraGpYYgSEOJQROIFkFqhCbaDbRpYkhZI7ZLhWxaGSVehE2/XszIDMuu+2T+nGcy39cLBvY5z5/5zo+Z95w9M3NOdXcAmOU71j0AAMsTf4CBxB9gIPEHGEj8AQa6ed0DJMmJEyf69OnT6x4D4A3l6aeffrm7T+7luUci/qdPn86FCxfWPQbAG0pV/ften+uwD8BA4g8wkPgDDCT+AAOJP8BABx7/qnpHVf1ZVT180K8NwMFYKf5V9UBVvVRVz161/Y6qeqGqLlbVJ5Kku1/s7vsOY1gADsaqe/4PJrlj94aquinJJ5PcmeRMknur6syBTgfAoVgp/t39RJJvXbX5vUkubu/pv5rkoST3rPqOq+pcVV2oqguXL19eeWAA9m8/x/xPJfn6rtuXkpyqqrdW1f1JfrSqfvt6T+7u8919trvPnjy5p79OBmCP9nN6h7rGtu7ubyb56D5eF4BDtp89/0tJ3rbr9q1JvrG/cQBYwn7i/8Uk76yq26rqliQfTPLowYwFwGFa9Vc9P5PkySS3V9Wlqrqvu68k+ViSzyV5Pslnu/u5wxsVgIOy0jH/7r73OtsfT/L4gU4EwKFzegeAgcQfYKC1xr+q7q6q85ubm+scA2Cctca/ux/r7nMbGxvrHANgHId9AAYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGMhf+AIM5C98AQZy2AdgIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGMi5fQAGcm4fgIEc9gEYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIGc2A1gICd2AxjIYR+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDn8wcYyPn8AQZy2AdgIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIJdxBBjIZRwBBnLYB2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBhJ/gIHEH2Ag8QcYSPwBBlpr/Kvq7qo6v7m5uc4xAMZZa/y7+7HuPrexsbHOMQDGcdgHYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgcQfYCDxBxhI/AEGEn+AgdYa/6q6u6rOb25urnMMgHHWGv/ufqy7z21sbKxzDIBxHPYBGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBxB9gIPEHGEj8AQYSf4CBbj7oF6yq70nyqSSvJvl8d//FQb8PAPZnpT3/qnqgql6qqmev2n5HVb1QVRer6hPbm385ycPd/etJfvGA5wXgAKx62OfBJHfs3lBVNyX5ZJI7k5xJcm9VnUlya5Kvbz/stYMZE4CDtFL8u/uJJN+6avN7k1zs7he7+9UkDyW5J8mlbH0D+H9fv6rOVdWFqrpw+fLl1z85AHu2nx/4nsrOHn6yFf1TSR5J8itV9adJHrvek7v7fHef7e6zJ0+e3McYALxe+/mBb11jW3f3K0k+so/XBeCQ7WfP/1KSt+26fWuSb+xvHACWsJ/4fzHJO6vqtqq6JckHkzx6MGMBcJhW/VXPzyR5MsntVXWpqu7r7itJPpbkc0meT/LZ7n7u8EYF4KCsdMy/u++9zvbHkzx+oBMBcOic3gFgIPEHGGit8a+qu6vq/Obm5jrHABinunvdM6Sq/jvJC+ue44g4keTldQ9xRFiLHdZih7XYcXt3v2kvTzzws3ru0QvdfXbdQxwFVXXBWmyxFjusxQ5rsaOqLuz1uY75Awwk/gADHZX4n1/3AEeItdhhLXZYix3WYsee1+JI/MAXgGUdlT1/ABYk/gADLRr/61zzd/f9VVV/vH3/M1X1niXnW9IKa/Gr22vwTFV9oarevY45l3Cjtdj1uB+vqteq6gNLzrekVdaiqt5fVV+qqueq6h+WnnEJK3x9bFTVY1X15e11OLbXELneNdR33b+3bnb3Im9Jbkryr0nekeSWJF9Ocuaqx9yV5G+ydaGY9yX5p6XmW/JtxbX4ySRv2f73nZPXYtfj/j5bJxL8wLrnXuPnxZuT/EuSt2/f/r51z72mdfidJH+4/e+T2brM7C3rnv2Q1uNnkrwnybPXuX9P3Vxyz/961/zd7Z4kf95bnkry5qr6gQVnXMoN16K7v9Dd/7l986nsXBf5uFnl8yJJfjPJXyZ5acnhFrbKWnwoySPd/bUk6e7juB6rrEMneVNVVZLvzVb8ryw75jL62tdQ321P3Vwy/te75u/rfcxx8Ho/zvuy9Z39OLrhWlTVqSS/lOT+Bedah1U+L34oyVuq6vNV9XRVfXix6Zazyjr8SZJ3ZevqgV9J8lvd/e1lxjty9tTNJU/vcM1r/u7hMcfByh9nVf1stuL/U4c60fqsshZ/lOTj3f3a1o7esbXKWtyc5MeS/HyS70ryZFU91d1fPezhFrTKOvxCki8l+bkkP5jk76rqH7v7vw55tqNoT91cMv6rXPN3ynWBV/o4q+pHknw6yZ3d/c2FZlvaKmtxNslD2+E/keSuqrrS3X+1yITLWfVr5OXufiXJK1X1RJJ3JzlO8V9lHT6S5A9666D3xar6tyQ/nOSflxnxSNlTN5c87LPKNX8fTfLh7Z9evy/JZnf/x4IzLuWGa1FVb0/ySJJfO2Z7dVe74Vp0923dfbq7Tyd5OMlvHMPwJ6t9jfx1kp+uqpur6ruT/ES2LqN6nKyyDl/L1v9+UlXfn+T2JC8uOuXRsaduLrbn391Xqur/rvl7U5IHuvu5qvro9v33Z+s3Oe5KcjHJ/2Tru/uxs+Ja/G6Styb51PYe75U+hmcyXHEtRlhlLbr7+ar62yTPJPl2kk939zV/BfCNasXPid9P8mBVfSVbhz0+3t3H8jTP29dQf3+SE1V1KcnvJfnOZH/ddHoHgIH8hS/AQOIPMJD4Awwk/gADiT/AQOIPMJD4Awz0v5mvhFcBrwQXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# plt.plot(history_2.history['loss'])\n",
    "# plt.plot(history_2.history['val_loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a964a60-488a-431e-8bcc-586e90d8956b",
   "metadata": {
    "id": "8a964a60-488a-431e-8bcc-586e90d8956b"
   },
   "outputs": [],
   "source": [
    "# y_pred = CNN.predict(X_test)\n",
    "# # y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a89bd1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_model = model.predict(X_test)\n",
    "y_pred_model= np.argmax(y_pred_model, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7C0QyTLHO8q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7C0QyTLHO8q",
    "outputId": "78587010-2aa8-4cc7-e82f-7c40e11ce705"
   },
   "outputs": [],
   "source": [
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ljWvGo9skgS",
   "metadata": {
    "id": "1ljWvGo9skgS"
   },
   "outputs": [],
   "source": [
    "# y_pred= np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIninuG_Hixu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIninuG_Hixu",
    "outputId": "8d52a3ce-46d5-41c3-f339-ec8e2feee684"
   },
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NzoyhrD4tO9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NzoyhrD4tO9",
    "outputId": "da09ab77-c439-431e-82a8-93fc98f20b49"
   },
   "outputs": [],
   "source": [
    "# y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57",
   "metadata": {
    "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57"
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'y_test': y_test.ravel().astype(int).tolist(),\n",
    "#     'y_pred': y_pred.ravel().astype(int).tolist(),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame({\n",
    "    'y_test': y_test.ravel().astype(int).tolist(),\n",
    "    'y_pred': y_pred_model.ravel().astype(int).tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
    "outputId": "aa49cb9d-c88e-437b-9a31-2809577d1da1"
   },
   "outputs": [],
   "source": [
    "# pd.crosstab(df['y_test'], df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_model['y_test'], df_model['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f",
   "metadata": {
    "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f"
   },
   "outputs": [],
   "source": [
    "model.save('model_f_s_90_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZD1w6TZwk0e",
   "metadata": {
    "id": "vZD1w6TZwk0e"
   },
   "outputs": [],
   "source": [
    "# CNN.save('model2testar_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413c816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f112bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad8cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e30e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
