{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2",
   "metadata": {
    "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from numpy.random import default_rng\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1",
   "metadata": {
    "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline params.\n",
    "DATA_PATH = Path('data')\n",
    "FILENAME_STOP = 'stop_90_diff_quat.csv'\n",
    "FILENAME_0 = '0_90_diff_quat.csv'\n",
    "FILENAME_90 = '90_90_diff_quat.csv'\n",
    "FILENAME_180 = '180_90_diff_quat.csv'\n",
    "FILENAME_270 = '270_90_diff_quat.csv'\n",
    "\n",
    "NUM_TIMESTEPS = 6\n",
    "IGNORE_FRACTION = 0.1\n",
    "TEST_FRACTION = 0.25\n",
    "\n",
    "# Training params.\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f52716d-1339-4484-9fd3-d5206979ba8e",
   "metadata": {
    "id": "7f52716d-1339-4484-9fd3-d5206979ba8e"
   },
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    num_timesteps,\n",
    "    ignore_fraction,\n",
    "    test_fraction,\n",
    "):\n",
    "\n",
    "    def read_and_prepare_data(\n",
    "        path,\n",
    "        class_,\n",
    "        num_timesteps,\n",
    "        ignore_fraction,\n",
    "        test_fraction,\n",
    "    ):\n",
    "\n",
    "        def split_temporally(X, test_fraction):\n",
    "            num_samples = X.shape[0]\n",
    "            num_train = int(num_samples * (1.0 - test_fraction))\n",
    "            X_train, X_test = X[:num_train], X[num_train:]\n",
    "            return X_train, X_test\n",
    "\n",
    "        def transform_into_sequences(X, num_timesteps):\n",
    "            num_samples = X.shape[0]\n",
    "            X_seq = []\n",
    "            for k in range(num_samples - num_timesteps + 1):\n",
    "                X_seq.append(X[k:(k + num_timesteps)])\n",
    "            X_seq = np.array(X_seq)\n",
    "            y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "            return X_seq, y_seq\n",
    "\n",
    "        X = pd.read_csv(path).values\n",
    "        X = X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]]  # Use only feet translations.\n",
    "\n",
    "        # Ignore beginning and end.\n",
    "        num_samples = X.shape[0]\n",
    "        num_ignore = int(ignore_fraction * num_samples)\n",
    "        X = X[num_ignore:-num_ignore]\n",
    "\n",
    "        # Split X temporally.\n",
    "        X_train, X_test = split_temporally(X, test_fraction)\n",
    "\n",
    "        # Transform X into short sequences.\n",
    "        X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "        X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def shuffle_data(X, y):\n",
    "        idx = np.arange(len(X))\n",
    "        default_rng().shuffle(idx)\n",
    "        X_shuffled = X[idx, :]\n",
    "        y_shuffled = y[idx]\n",
    "        return X_shuffled, y_shuffled\n",
    "\n",
    "    X_train_stop, y_train_stop, X_test_stop, y_test_stop = \\\n",
    "        read_and_prepare_data(\n",
    "            path_stop,\n",
    "            0.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_0, y_train_0, X_test_0, y_test_0 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_0,\n",
    "            1.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train_90, y_train_90, X_test_90, y_test_90 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_90,\n",
    "            2.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_180, y_train_180, X_test_180, y_test_180 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_180,\n",
    "            3.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_270, y_train_270, X_test_270, y_test_270 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_270,\n",
    "            4.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train = np.concatenate((X_train_stop, X_train_0, X_train_90, X_train_180, X_train_270), axis=0)\n",
    "    y_train = np.concatenate((y_train_stop, y_train_0, y_train_90, y_train_180, y_train_270), axis=0)\n",
    "    X_test = np.concatenate((X_test_stop, X_test_0, X_test_90, X_test_180, X_test_270), axis=0)\n",
    "    y_test = np.concatenate((y_test_stop, y_test_0, y_test_90, y_test_180, y_test_270), axis=0)\n",
    "\n",
    "    X_train, y_train = shuffle_data(X_train, y_train)\n",
    "    X_test, y_test = shuffle_data(X_test, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "path_0 = Path(DATA_PATH, FILENAME_0)\n",
    "path_90 = Path(DATA_PATH, FILENAME_90)\n",
    "path_180 = Path(DATA_PATH, FILENAME_180)\n",
    "path_270 = Path(DATA_PATH, FILENAME_270)\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    NUM_TIMESTEPS,\n",
    "    IGNORE_FRACTION,\n",
    "    TEST_FRACTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c35712-1089-44f3-89ef-ed471b144c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99c35712-1089-44f3-89ef-ed471b144c96",
    "outputId": "9076061a-8661-4d2e-c1ed-887a92ec640b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100773, 6, 14), (100773, 1), (33575, 6, 14), (33575, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VqSuqgBCB_nA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqSuqgBCB_nA",
    "outputId": "26d50bbe-3fd3-4bed-e70e-7003d289c5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[60].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dye8vjENBtXX",
   "metadata": {
    "id": "dye8vjENBtXX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3TttkaRCM4l",
   "metadata": {
    "id": "-3TttkaRCM4l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a85634b-4e9c-45b8-b456-cb970457302f",
   "metadata": {
    "id": "3a85634b-4e9c-45b8-b456-cb970457302f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 2, 4, 256)         1280      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                49216     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,741\n",
      "Trainable params: 52,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "CNN = Sequential(name=\"Sequential_CNN\")\n",
    "\n",
    "CNN.add(Conv2D(256, kernel_size=(2, 2),\n",
    "               strides=(4, 4), padding=\"same\",\n",
    "               activation=\"selu\", input_shape=[6, 14, 1]))\n",
    "\n",
    "CNN.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),\n",
    "                     padding=\"valid\"))\n",
    "\n",
    "# Add another pair of Conv2D and MaxPooling2D for more model depth,\n",
    "# followed by the flatten and multiple dense layers\n",
    "\n",
    "# CNN.add(Conv2D(64, kernel_size=(3, 3),\n",
    "#                strides=(1, 1), padding=\"same\",\n",
    "#                activation=\"selu\"))\n",
    "\n",
    "# CNN.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),\n",
    "#                      padding=\"valid\"))\n",
    "\n",
    "CNN.add(Flatten())\n",
    "\n",
    "CNN.add(Dense(64, activation='selu'))\n",
    "CNN.add(Dense(32, activation='selu'))\n",
    "CNN.add(Dense(5, activation='softmax'))\n",
    "\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0C2RSxICKzq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0C2RSxICKzq",
    "outputId": "af853522-fdf6-40e4-8d0e-cd2a6dcdab9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "911581af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "where_are_NaNsx = isnan(X_train)\n",
    "X_train[where_are_NaNsx] = 0\n",
    "\n",
    "where_are_NaNsy = isnan(y_train)\n",
    "y_train[where_are_NaNsy] = 0\n",
    "\n",
    "where_are_NaNsxt = isnan(X_test)\n",
    "X_test[where_are_NaNsxt] = 0\n",
    "\n",
    "where_are_NaNsyt = isnan(y_test)\n",
    "y_test[where_are_NaNsyt] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7baf8970-5318-4461-b828-d34c232afa5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7baf8970-5318-4461-b828-d34c232afa5f",
    "outputId": "08a66cc8-aeee-42ba-f039-9dfa2ba6f99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "394/394 [==============================] - 8s 17ms/step - loss: 0.7563 - accuracy: 0.6851 - val_loss: 0.5051 - val_accuracy: 0.7763\n",
      "Epoch 2/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.5211 - accuracy: 0.7984 - val_loss: 0.4094 - val_accuracy: 0.8389\n",
      "Epoch 3/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.4188 - accuracy: 0.8432 - val_loss: 0.3070 - val_accuracy: 0.8647\n",
      "Epoch 4/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.3550 - accuracy: 0.8701 - val_loss: 0.2644 - val_accuracy: 0.8877\n",
      "Epoch 5/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.3053 - accuracy: 0.8872 - val_loss: 0.2207 - val_accuracy: 0.9004\n",
      "Epoch 6/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.2779 - accuracy: 0.8953 - val_loss: 0.2290 - val_accuracy: 0.8973\n",
      "Epoch 7/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.2667 - accuracy: 0.8977 - val_loss: 0.2262 - val_accuracy: 0.8988\n",
      "Epoch 8/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.2491 - accuracy: 0.9027 - val_loss: 0.2051 - val_accuracy: 0.9121\n",
      "Epoch 9/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.2425 - accuracy: 0.9054 - val_loss: 0.1977 - val_accuracy: 0.9116\n",
      "Epoch 10/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.2320 - accuracy: 0.9076 - val_loss: 0.1888 - val_accuracy: 0.9115\n",
      "Epoch 11/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.2164 - accuracy: 0.9138 - val_loss: 0.1821 - val_accuracy: 0.9157\n",
      "Epoch 12/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.2153 - accuracy: 0.9139 - val_loss: 0.2010 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.2052 - accuracy: 0.9175 - val_loss: 0.2160 - val_accuracy: 0.9145\n",
      "Epoch 14/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.2045 - accuracy: 0.9188 - val_loss: 0.1826 - val_accuracy: 0.9138\n",
      "Epoch 15/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.2006 - accuracy: 0.9202 - val_loss: 0.2062 - val_accuracy: 0.9123\n",
      "Epoch 16/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.2124 - accuracy: 0.9166 - val_loss: 0.1856 - val_accuracy: 0.9126\n",
      "Epoch 17/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1860 - accuracy: 0.9252 - val_loss: 0.2055 - val_accuracy: 0.9110\n",
      "Epoch 18/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.2064 - val_accuracy: 0.9106\n",
      "Epoch 19/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.1874 - accuracy: 0.9268 - val_loss: 0.1803 - val_accuracy: 0.9214\n",
      "Epoch 20/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1816 - accuracy: 0.9295 - val_loss: 0.2185 - val_accuracy: 0.9122\n",
      "Epoch 21/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.1775 - accuracy: 0.9316 - val_loss: 0.1988 - val_accuracy: 0.9180\n",
      "Epoch 22/100\n",
      "394/394 [==============================] - 7s 19ms/step - loss: 0.1799 - accuracy: 0.9315 - val_loss: 0.1817 - val_accuracy: 0.9244\n",
      "Epoch 23/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1753 - accuracy: 0.9336 - val_loss: 0.1951 - val_accuracy: 0.9230\n",
      "Epoch 24/100\n",
      "394/394 [==============================] - 8s 19ms/step - loss: 0.1677 - accuracy: 0.9355 - val_loss: 0.2326 - val_accuracy: 0.9112\n",
      "Epoch 25/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1739 - accuracy: 0.9348 - val_loss: 0.1913 - val_accuracy: 0.9208\n",
      "Epoch 26/100\n",
      "394/394 [==============================] - 8s 21ms/step - loss: 0.1732 - accuracy: 0.9348 - val_loss: 0.2062 - val_accuracy: 0.9144\n",
      "Epoch 27/100\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.1673 - accuracy: 0.9373 - val_loss: 0.1645 - val_accuracy: 0.9316\n",
      "Epoch 28/100\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.1603 - accuracy: 0.9405 - val_loss: 0.1963 - val_accuracy: 0.9261\n",
      "Epoch 29/100\n",
      "394/394 [==============================] - 8s 20ms/step - loss: 0.1626 - accuracy: 0.9394 - val_loss: 0.1718 - val_accuracy: 0.9343\n",
      "Epoch 30/100\n",
      "394/394 [==============================] - 8s 21ms/step - loss: 0.1547 - accuracy: 0.9433 - val_loss: 0.1852 - val_accuracy: 0.9277\n",
      "Epoch 31/100\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.1571 - accuracy: 0.9414 - val_loss: 0.1943 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "394/394 [==============================] - 8s 20ms/step - loss: 0.1544 - accuracy: 0.9431 - val_loss: 0.1761 - val_accuracy: 0.9288\n",
      "Epoch 33/100\n",
      "394/394 [==============================] - 7s 19ms/step - loss: 0.1541 - accuracy: 0.9440 - val_loss: 0.1784 - val_accuracy: 0.9336\n",
      "Epoch 34/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.1473 - accuracy: 0.9459 - val_loss: 0.2077 - val_accuracy: 0.9209\n",
      "Epoch 35/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1476 - accuracy: 0.9466 - val_loss: 0.1911 - val_accuracy: 0.9239\n",
      "Epoch 36/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1441 - accuracy: 0.9472 - val_loss: 0.1971 - val_accuracy: 0.9246\n",
      "Epoch 37/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1458 - accuracy: 0.9469 - val_loss: 0.1622 - val_accuracy: 0.9408\n",
      "Epoch 38/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1478 - accuracy: 0.9458 - val_loss: 0.1832 - val_accuracy: 0.9341\n",
      "Epoch 39/100\n",
      "394/394 [==============================] - 10s 25ms/step - loss: 0.1412 - accuracy: 0.9488 - val_loss: 0.1952 - val_accuracy: 0.9277\n",
      "Epoch 40/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1455 - accuracy: 0.9478 - val_loss: 0.1597 - val_accuracy: 0.9432\n",
      "Epoch 41/100\n",
      "394/394 [==============================] - 8s 20ms/step - loss: 0.1401 - accuracy: 0.9497 - val_loss: 0.1662 - val_accuracy: 0.9377\n",
      "Epoch 42/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1366 - accuracy: 0.9511 - val_loss: 0.1762 - val_accuracy: 0.9336\n",
      "Epoch 43/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.1364 - accuracy: 0.9508 - val_loss: 0.1834 - val_accuracy: 0.9317\n",
      "Epoch 44/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1302 - accuracy: 0.9536 - val_loss: 0.2981 - val_accuracy: 0.9053\n",
      "Epoch 45/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1433 - accuracy: 0.9499 - val_loss: 0.1902 - val_accuracy: 0.9263\n",
      "Epoch 46/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1279 - accuracy: 0.9548 - val_loss: 0.1882 - val_accuracy: 0.9347\n",
      "Epoch 47/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.1289 - accuracy: 0.9539 - val_loss: 0.1880 - val_accuracy: 0.9354\n",
      "Epoch 48/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.1295 - accuracy: 0.9542 - val_loss: 0.1898 - val_accuracy: 0.9291\n",
      "Epoch 49/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1260 - accuracy: 0.9550 - val_loss: 0.1616 - val_accuracy: 0.9438\n",
      "Epoch 50/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1255 - accuracy: 0.9558 - val_loss: 0.2280 - val_accuracy: 0.9211\n",
      "Epoch 51/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.1419 - accuracy: 0.9505 - val_loss: 0.1729 - val_accuracy: 0.9409\n",
      "Epoch 52/100\n",
      "394/394 [==============================] - 8s 20ms/step - loss: 0.1224 - accuracy: 0.9575 - val_loss: 0.1676 - val_accuracy: 0.9420\n",
      "Epoch 53/100\n",
      "394/394 [==============================] - 8s 19ms/step - loss: 0.1245 - accuracy: 0.9556 - val_loss: 0.1598 - val_accuracy: 0.9433\n",
      "Epoch 54/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.1208 - accuracy: 0.9572 - val_loss: 0.1610 - val_accuracy: 0.9421\n",
      "Epoch 55/100\n",
      "394/394 [==============================] - 7s 18ms/step - loss: 0.1236 - accuracy: 0.9568 - val_loss: 0.1885 - val_accuracy: 0.9341\n",
      "Epoch 56/100\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.1206 - accuracy: 0.9576 - val_loss: 0.1578 - val_accuracy: 0.9467\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 10s 26ms/step - loss: 0.1177 - accuracy: 0.9591 - val_loss: 0.1779 - val_accuracy: 0.9361\n",
      "Epoch 58/100\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.1206 - accuracy: 0.9579 - val_loss: 0.1662 - val_accuracy: 0.9454\n",
      "Epoch 59/100\n",
      "394/394 [==============================] - 9s 23ms/step - loss: 0.1148 - accuracy: 0.9599 - val_loss: 0.1699 - val_accuracy: 0.9403\n",
      "Epoch 60/100\n",
      "394/394 [==============================] - 8s 21ms/step - loss: 0.1153 - accuracy: 0.9598 - val_loss: 0.1680 - val_accuracy: 0.9407\n",
      "Epoch 61/100\n",
      "394/394 [==============================] - 8s 19ms/step - loss: 0.1154 - accuracy: 0.9599 - val_loss: 0.1548 - val_accuracy: 0.9452\n",
      "Epoch 62/100\n",
      "394/394 [==============================] - 7s 17ms/step - loss: 0.1142 - accuracy: 0.9605 - val_loss: 0.1791 - val_accuracy: 0.9389\n",
      "Epoch 63/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.1146 - accuracy: 0.9602 - val_loss: 0.1728 - val_accuracy: 0.9403\n",
      "Epoch 64/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1186 - accuracy: 0.9596 - val_loss: 0.1958 - val_accuracy: 0.9322\n",
      "Epoch 65/100\n",
      "394/394 [==============================] - 6s 16ms/step - loss: 0.1132 - accuracy: 0.9608 - val_loss: 0.1367 - val_accuracy: 0.9552\n",
      "Epoch 66/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.1118 - accuracy: 0.9616 - val_loss: 0.1495 - val_accuracy: 0.9504\n",
      "Epoch 67/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1099 - accuracy: 0.9620 - val_loss: 0.1506 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.1218 - accuracy: 0.9580 - val_loss: 0.1604 - val_accuracy: 0.9439\n",
      "Epoch 69/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1040 - accuracy: 0.9640 - val_loss: 0.1729 - val_accuracy: 0.9462\n",
      "Epoch 70/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1084 - accuracy: 0.9624 - val_loss: 0.1475 - val_accuracy: 0.9518\n",
      "Epoch 71/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1095 - accuracy: 0.9625 - val_loss: 0.1505 - val_accuracy: 0.9517\n",
      "Epoch 72/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1065 - accuracy: 0.9637 - val_loss: 0.1387 - val_accuracy: 0.9537\n",
      "Epoch 73/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1090 - accuracy: 0.9623 - val_loss: 0.2369 - val_accuracy: 0.9308\n",
      "Epoch 74/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1074 - accuracy: 0.9633 - val_loss: 0.1403 - val_accuracy: 0.9546\n",
      "Epoch 75/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1057 - accuracy: 0.9638 - val_loss: 0.1573 - val_accuracy: 0.9515\n",
      "Epoch 76/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1090 - accuracy: 0.9631 - val_loss: 0.1372 - val_accuracy: 0.9570\n",
      "Epoch 77/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1028 - accuracy: 0.9647 - val_loss: 0.1505 - val_accuracy: 0.9531\n",
      "Epoch 78/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.1037 - accuracy: 0.9643 - val_loss: 0.1597 - val_accuracy: 0.9512\n",
      "Epoch 79/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1060 - accuracy: 0.9642 - val_loss: 0.1633 - val_accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1033 - accuracy: 0.9646 - val_loss: 0.1442 - val_accuracy: 0.9567\n",
      "Epoch 81/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0995 - accuracy: 0.9659 - val_loss: 0.1536 - val_accuracy: 0.9510\n",
      "Epoch 82/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1011 - accuracy: 0.9653 - val_loss: 0.1469 - val_accuracy: 0.9552\n",
      "Epoch 83/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 0.1549 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0995 - accuracy: 0.9656 - val_loss: 0.1520 - val_accuracy: 0.9540\n",
      "Epoch 85/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0974 - accuracy: 0.9660 - val_loss: 0.1633 - val_accuracy: 0.9459\n",
      "Epoch 86/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1042 - accuracy: 0.9642 - val_loss: 0.1444 - val_accuracy: 0.9574\n",
      "Epoch 87/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.1092 - accuracy: 0.9638 - val_loss: 0.1421 - val_accuracy: 0.9585\n",
      "Epoch 88/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.0950 - accuracy: 0.9670 - val_loss: 0.1466 - val_accuracy: 0.9567\n",
      "Epoch 89/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0953 - accuracy: 0.9676 - val_loss: 0.1584 - val_accuracy: 0.9557\n",
      "Epoch 90/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0975 - accuracy: 0.9668 - val_loss: 0.1566 - val_accuracy: 0.9474\n",
      "Epoch 91/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.0934 - accuracy: 0.9678 - val_loss: 0.1364 - val_accuracy: 0.9590\n",
      "Epoch 92/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.1049 - accuracy: 0.9650 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "394/394 [==============================] - 5s 14ms/step - loss: 0.0914 - accuracy: 0.9686 - val_loss: 0.1525 - val_accuracy: 0.9513\n",
      "Epoch 94/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.0931 - accuracy: 0.9684 - val_loss: 0.1495 - val_accuracy: 0.9553\n",
      "Epoch 95/100\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.0956 - accuracy: 0.9679 - val_loss: 0.1503 - val_accuracy: 0.9523\n",
      "Epoch 96/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.0969 - accuracy: 0.9676 - val_loss: 0.1524 - val_accuracy: 0.9511\n",
      "Epoch 97/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.0927 - accuracy: 0.9683 - val_loss: 0.1469 - val_accuracy: 0.9585\n",
      "Epoch 98/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.0935 - accuracy: 0.9680 - val_loss: 0.1439 - val_accuracy: 0.9573\n",
      "Epoch 99/100\n",
      "394/394 [==============================] - 6s 14ms/step - loss: 0.0931 - accuracy: 0.9684 - val_loss: 0.1444 - val_accuracy: 0.9560\n",
      "Epoch 100/100\n",
      "394/394 [==============================] - 6s 15ms/step - loss: 0.0916 - accuracy: 0.9689 - val_loss: 0.1501 - val_accuracy: 0.9576\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "CNN.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = CNN.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
    "outputId": "7211ef5c-5b4a-4afb-ad4f-7341eeb8f0f8"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "_, num_time, num_feat = X_train.shape\n",
    "\n",
    "activation = 'selu'\n",
    "\n",
    "DefaultConv1D = partial(\n",
    "    keras.layers.Conv1D,\n",
    "    kernel_size=1,\n",
    "    activation=activation,\n",
    "    padding=\"valid\",\n",
    ")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv1D(4 * num_feat, kernel_size=2, input_shape=[num_time, num_feat]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    DefaultConv1D(num_feat, kernel_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(num_time * num_feat, activation=activation),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(num_feat, activation=activation),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(5, activation='softmax'),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
    "outputId": "4354cc75-e44d-4d2a-ac4b-c55a4b3a9305"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
    "outputId": "97e18fb9-4340-478c-e307-82c03282e9cc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'][10:])\n",
    "plt.plot(history.history['val_loss'][10:])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a964a60-488a-431e-8bcc-586e90d8956b",
   "metadata": {
    "id": "8a964a60-488a-431e-8bcc-586e90d8956b"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7C0QyTLHO8q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7C0QyTLHO8q",
    "outputId": "78587010-2aa8-4cc7-e82f-7c40e11ce705"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ljWvGo9skgS",
   "metadata": {
    "id": "1ljWvGo9skgS"
   },
   "outputs": [],
   "source": [
    "y_pred= np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BIninuG_Hixu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIninuG_Hixu",
    "outputId": "8d52a3ce-46d5-41c3-f339-ec8e2feee684"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NzoyhrD4tO9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NzoyhrD4tO9",
    "outputId": "da09ab77-c439-431e-82a8-93fc98f20b49"
   },
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57",
   "metadata": {
    "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_test': y_test.ravel().astype(int).tolist(),\n",
    "    'y_pred': y_pred.ravel().astype(int).tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
    "outputId": "aa49cb9d-c88e-437b-9a31-2809577d1da1"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['y_test'], df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f",
   "metadata": {
    "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZD1w6TZwk0e",
   "metadata": {
    "id": "vZD1w6TZwk0e"
   },
   "outputs": [],
   "source": [
    "CNN.save('model_90_95_accuracy.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
