{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2",
   "metadata": {
    "id": "b41f0b0f-cc96-43a2-ab7f-f3264587e7d2"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from numpy.random import default_rng\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1",
   "metadata": {
    "id": "c9e9560b-749a-49a8-aedf-44a1ac9b4bb1"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline params.\n",
    "DATA_PATH = Path('data')\n",
    "FILENAME_STOP = 'stop_90_diff_quat.csv'\n",
    "FILENAME_0 = '0_90_diff_quat.csv'\n",
    "FILENAME_90 = '90_90_diff_quat.csv'\n",
    "FILENAME_180 = '180_90_diff_quat.csv'\n",
    "FILENAME_270 = '270_90_diff_quat.csv'\n",
    "\n",
    "# # Loading pipeline params.\n",
    "# DATA_PATH = Path('data')\n",
    "# FILENAME_STOP = 'stop.csv'\n",
    "# FILENAME_0 = 'm_0.csv'\n",
    "# FILENAME_90 = 'm_90.csv'\n",
    "# FILENAME_180 = 'm_180.csv'\n",
    "# FILENAME_270 = 'm_270.csv'\n",
    "\n",
    "\n",
    "NUM_TIMESTEPS = 6\n",
    "IGNORE_FRACTION = 0.1\n",
    "TEST_FRACTION = 0.25\n",
    "VALIDATION_FRACTION = 0.25\n",
    "\n",
    "\n",
    "# Training params.\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bbdba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    num_timesteps,\n",
    "    ignore_fraction,\n",
    "    test_fraction,\n",
    "):\n",
    "\n",
    "    def read_and_prepare_data(\n",
    "        path,\n",
    "        class_,\n",
    "        num_timesteps,\n",
    "        ignore_fraction,\n",
    "        test_fraction,\n",
    "    ):\n",
    "\n",
    "        def split_temporally(X, test_fraction):\n",
    "            num_samples = X.shape[0]\n",
    "            num_train = int(num_samples * (1.0 - test_fraction))\n",
    "            X_train, X_test = X[:num_train], X[num_train:]\n",
    "            return X_train, X_test\n",
    "\n",
    "        def transform_into_sequences(X, num_timesteps):\n",
    "            num_samples = X.shape[0]\n",
    "            X_seq = []\n",
    "            for k in range(num_samples - num_timesteps + 1):\n",
    "                X_seq.append(X[k:(k + num_timesteps)])\n",
    "            X_seq = np.array(X_seq)\n",
    "            y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "            return X_seq, y_seq\n",
    "\n",
    "        X = pd.read_csv(path).values\n",
    "        X = X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "\n",
    "        # Ignore beginning and end.\n",
    "        num_samples = X.shape[0]\n",
    "        num_ignore = int(ignore_fraction * num_samples)\n",
    "        X = X[num_ignore:-num_ignore]\n",
    "\n",
    "        # Split X temporally.\n",
    "        X_train, X_test = split_temporally(X, test_fraction)\n",
    "        \n",
    "        # Transform X into short sequences.\n",
    "        X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "        X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "    def shuffle_data(X, y):\n",
    "        idx = np.arange(len(X))\n",
    "        default_rng().shuffle(idx)\n",
    "        X_shuffled = X[idx, :]\n",
    "        y_shuffled = y[idx]\n",
    "        return X_shuffled, y_shuffled\n",
    "\n",
    "    X_train_stop, y_train_stop, X_test_stop, y_test_stop, X_val_stop, y_val_stop = \\\n",
    "        read_and_prepare_data(\n",
    "            path_stop,\n",
    "            0.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_0, y_train_0, X_test_0, y_test_0, X_val_0, y_val_0 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_0,\n",
    "            1.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train_90, y_train_90, X_test_90, y_test_90, X_val_90, y_val_90 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_90,\n",
    "            2.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_180, y_train_180, X_test_180, y_test_180, X_val_180, y_val_180 = \\\n",
    "        read_and_prepare_data(\n",
    "            path_180,\n",
    "            3.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "    \n",
    "    X_train_270, y_train_270, X_test_270, y_test_270,X_val_270, y_val_270  = \\\n",
    "        read_and_prepare_data(\n",
    "            path_270,\n",
    "            4.0,\n",
    "            num_timesteps,\n",
    "            ignore_fraction,\n",
    "            test_fraction,\n",
    "        )\n",
    "\n",
    "    X_train = np.concatenate((X_train_stop, X_train_0, X_train_90, X_train_180, X_train_270), axis=0)\n",
    "    y_train = np.concatenate((y_train_stop, y_train_0, y_train_90, y_train_180, y_train_270), axis=0)\n",
    "    X_test = np.concatenate((X_test_stop, X_test_0, X_test_90, X_test_180, X_test_270), axis=0)\n",
    "    y_test = np.concatenate((y_test_stop, y_test_0, y_test_90, y_test_180, y_test_270), axis=0)\n",
    "    X_val = np.concatenate((X_val_stop, X_val_0, X_val_90, X_val_180, X_val_270), axis=0)\n",
    "    y_val = np.concatenate((y_val_stop, y_val_0, y_val_90, y_val_180, y_val_270), axis=0)\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train, y_train = shuffle_data(X_train, y_train)\n",
    "    X_test, y_test = shuffle_data(X_test, y_test)\n",
    "    X_val, y_val = shuffle_data(X_val, y_val)\n",
    "    return X_train, X_test,X_val, y_train, y_test, y_val\n",
    "\n",
    "\n",
    "path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "path_0 = Path(DATA_PATH, FILENAME_0)\n",
    "path_90 = Path(DATA_PATH, FILENAME_90)\n",
    "path_180 = Path(DATA_PATH, FILENAME_180)\n",
    "path_270 = Path(DATA_PATH, FILENAME_270)\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test , y_val= load_data(\n",
    "    path_stop,\n",
    "    path_0,\n",
    "    path_90,\n",
    "    path_180,\n",
    "    path_270,\n",
    "    NUM_TIMESTEPS,\n",
    "    IGNORE_FRACTION,\n",
    "    TEST_FRACTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f52716d-1339-4484-9fd3-d5206979ba8e",
   "metadata": {
    "id": "7f52716d-1339-4484-9fd3-d5206979ba8e"
   },
   "outputs": [],
   "source": [
    "# def load_data(\n",
    "#     path_stop,\n",
    "#     path_0,\n",
    "#     path_90,\n",
    "#     path_180,\n",
    "#     path_270,\n",
    "#     num_timesteps,\n",
    "#     ignore_fraction,\n",
    "#     test_fraction,\n",
    "# ):\n",
    "\n",
    "#     def read_and_prepare_data(\n",
    "#         path,\n",
    "#         class_,\n",
    "#         num_timesteps,\n",
    "#         ignore_fraction,\n",
    "#         test_fraction,\n",
    "#     ):\n",
    "\n",
    "#         def split_temporally(X, test_fraction):\n",
    "#             num_samples = X.shape[0]\n",
    "#             num_train = int(num_samples * (1.0 - test_fraction))\n",
    "#             X_train, X_test = X[:num_train], X[num_train:]\n",
    "#             return X_train, X_test\n",
    "\n",
    "#         def transform_into_sequences(X, num_timesteps):\n",
    "#             num_samples = X.shape[0]\n",
    "#             X_seq = []\n",
    "#             for k in range(num_samples - num_timesteps + 1):\n",
    "#                 X_seq.append(X[k:(k + num_timesteps)])\n",
    "#             X_seq = np.array(X_seq)\n",
    "#             y_seq = class_ * np.ones((X_seq.shape[0], 1))\n",
    "#             return X_seq, y_seq\n",
    "\n",
    "#         X = pd.read_csv(path).values\n",
    "#         X = X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "\n",
    "#         # Ignore beginning and end.\n",
    "#         num_samples = X.shape[0]\n",
    "#         num_ignore = int(ignore_fraction * num_samples)\n",
    "#         X = X[num_ignore:-num_ignore]\n",
    "\n",
    "#         # Split X temporally.\n",
    "#         X_train, X_test = split_temporally(X, test_fraction)\n",
    "\n",
    "#         # Transform X into short sequences.\n",
    "#         X_train, y_train = transform_into_sequences(X_train, num_timesteps)\n",
    "#         X_test, y_test = transform_into_sequences(X_test, num_timesteps)\n",
    "\n",
    "#         return X_train, y_train, X_test, y_test\n",
    "\n",
    "#     def shuffle_data(X, y):\n",
    "#         idx = np.arange(len(X))\n",
    "#         default_rng().shuffle(idx)\n",
    "#         X_shuffled = X[idx, :]\n",
    "#         y_shuffled = y[idx]\n",
    "#         return X_shuffled, y_shuffled\n",
    "\n",
    "#     X_train_stop, y_train_stop, X_test_stop, y_test_stop = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_stop,\n",
    "#             0.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_0, y_train_0, X_test_0, y_test_0 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_0,\n",
    "#             1.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "\n",
    "#     X_train_90, y_train_90, X_test_90, y_test_90 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_90,\n",
    "#             2.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_180, y_train_180, X_test_180, y_test_180 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_180,\n",
    "#             3.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "    \n",
    "#     X_train_270, y_train_270, X_test_270, y_test_270 = \\\n",
    "#         read_and_prepare_data(\n",
    "#             path_270,\n",
    "#             4.0,\n",
    "#             num_timesteps,\n",
    "#             ignore_fraction,\n",
    "#             test_fraction,\n",
    "#         )\n",
    "\n",
    "#     X_train = np.concatenate((X_train_stop, X_train_0, X_train_90, X_train_180, X_train_270), axis=0)\n",
    "#     y_train = np.concatenate((y_train_stop, y_train_0, y_train_90, y_train_180, y_train_270), axis=0)\n",
    "#     X_test = np.concatenate((X_test_stop, X_test_0, X_test_90, X_test_180, X_test_270), axis=0)\n",
    "#     y_test = np.concatenate((y_test_stop, y_test_0, y_test_90, y_test_180, y_test_270), axis=0)\n",
    "\n",
    "#     X_train, y_train = shuffle_data(X_train, y_train)\n",
    "#     X_test, y_test = shuffle_data(X_test, y_test)\n",
    "\n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# path_stop = Path(DATA_PATH, FILENAME_STOP)\n",
    "# path_0 = Path(DATA_PATH, FILENAME_0)\n",
    "# path_90 = Path(DATA_PATH, FILENAME_90)\n",
    "# path_180 = Path(DATA_PATH, FILENAME_180)\n",
    "# path_270 = Path(DATA_PATH, FILENAME_270)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = load_data(\n",
    "#     path_stop,\n",
    "#     path_0,\n",
    "#     path_90,\n",
    "#     path_180,\n",
    "#     path_270,\n",
    "#     NUM_TIMESTEPS,\n",
    "#     IGNORE_FRACTION,\n",
    "#     TEST_FRACTION,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c35712-1089-44f3-89ef-ed471b144c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99c35712-1089-44f3-89ef-ed471b144c96",
    "outputId": "9076061a-8661-4d2e-c1ed-887a92ec640b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100773, 6, 14), (100773, 1), (16785, 6, 14), (16785, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "VqSuqgBCB_nA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqSuqgBCB_nA",
    "outputId": "26d50bbe-3fd3-4bed-e70e-7003d289c5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16790, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dye8vjENBtXX",
   "metadata": {
    "id": "dye8vjENBtXX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3TttkaRCM4l",
   "metadata": {
    "id": "-3TttkaRCM4l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a85634b-4e9c-45b8-b456-cb970457302f",
   "metadata": {
    "id": "3a85634b-4e9c-45b8-b456-cb970457302f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 6, 14, 256)        2560      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                196672    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,477\n",
      "Trainable params: 201,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "CNN = Sequential(name=\"Sequential_CNN\")\n",
    "\n",
    "CNN.add(Conv2D(256, kernel_size=(3, 3),\n",
    "               strides=(1, 1), padding=\"same\",\n",
    "               activation=\"selu\", input_shape=[6, 14, 1]))\n",
    "\n",
    "CNN.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
    "                     padding=\"valid\"))\n",
    "\n",
    "# Add another pair of Conv2D and MaxPooling2D for more model depth,\n",
    "# followed by the flatten and multiple dense layers\n",
    "\n",
    "# CNN.add(Conv2D(64, kernel_size=(3, 3),\n",
    "#                strides=(1, 1), padding=\"same\",\n",
    "#                activation=\"selu\"))\n",
    "\n",
    "# CNN.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),\n",
    "#                      padding=\"valid\"))\n",
    "\n",
    "CNN.add(Flatten())\n",
    "\n",
    "CNN.add(Dense(64, activation='selu'))\n",
    "CNN.add(Dense(32, activation='selu'))\n",
    "CNN.add(Dense(5, activation='softmax'))\n",
    "\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j0C2RSxICKzq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0C2RSxICKzq",
    "outputId": "af853522-fdf6-40e4-8d0e-cd2a6dcdab9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "911581af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "where_are_NaNsx = isnan(X_train)\n",
    "X_train[where_are_NaNsx] = 0\n",
    "\n",
    "where_are_NaNsy = isnan(y_train)\n",
    "y_train[where_are_NaNsy] = 0\n",
    "\n",
    "where_are_NaNsxt = isnan(X_test)\n",
    "X_test[where_are_NaNsxt] = 0\n",
    "\n",
    "where_are_NaNsyt = isnan(y_test)\n",
    "y_test[where_are_NaNsyt] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7baf8970-5318-4461-b828-d34c232afa5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7baf8970-5318-4461-b828-d34c232afa5f",
    "outputId": "08a66cc8-aeee-42ba-f039-9dfa2ba6f99e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "394/394 [==============================] - 24s 60ms/step - loss: 0.0099 - categorical_accuracy: 0.4283 - val_loss: 0.0245 - val_categorical_accuracy: 0.4280\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 22s 55ms/step - loss: 0.0099 - categorical_accuracy: 0.4283 - val_loss: 0.0265 - val_categorical_accuracy: 0.4288\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 22s 55ms/step - loss: 0.0101 - categorical_accuracy: 0.4282 - val_loss: 0.0184 - val_categorical_accuracy: 0.4282\n",
      "Epoch 4/10\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.0081 - categorical_accuracy: 0.4283"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      3\u001b[0m CNN\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      6\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mCNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "CNN.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['categorical_accuracy'],\n",
    ")\n",
    "history = CNN.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70de8d27-4ff5-4dce-b45f-675dcc74513e",
    "outputId": "7211ef5c-5b4a-4afb-ad4f-7341eeb8f0f8"
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "# _, num_time, num_feat = X_train.shape\n",
    "\n",
    "# activation = 'selu'\n",
    "\n",
    "# DefaultConv1D = partial(\n",
    "#     keras.layers.Conv1D,\n",
    "#     kernel_size=1,\n",
    "#     activation=activation,\n",
    "#     padding=\"valid\",\n",
    "# )\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     DefaultConv1D(4 * num_feat, kernel_size=2, input_shape=[num_time, num_feat]),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     DefaultConv1D(num_feat, kernel_size=2),\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(num_time * num_feat, activation=activation),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(num_feat, activation=activation),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dense(5, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# model.compile(\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     optimizer=optimizer,\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     verbose=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b253f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # define the input shape\n",
    "# input_shape = (6, 14)\n",
    "\n",
    "# # create the input placeholder for the model\n",
    "# input_data = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# # reshape input data\n",
    "# input_data_reshaped = tf.keras.layers.Reshape((6, 14, 1))(input_data)\n",
    "\n",
    "# # define the convolutional layer\n",
    "# conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_data_reshaped)\n",
    "\n",
    "# # add maxpooling layer\n",
    "# maxpooling = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
    "\n",
    "\n",
    "# reshaped = tf.keras.layers.Reshape((2, 6*32))(maxpooling)\n",
    "\n",
    "# # define the recurrent layer\n",
    "# rnn = tf.keras.layers.GRU(units=64, return_sequences=True)(reshaped)\n",
    "\n",
    "# # define the fully connected layers\n",
    "\n",
    "\n",
    "# fc1 = tf.keras.layers.Dense(units=64, activation='relu')(rnn)\n",
    "# fc2 = tf.keras.layers.Dense(units=5, activation='softmax')(fc1)\n",
    "\n",
    "# # define the model\n",
    "# model = tf.keras.Model(inputs=input_data, outputs=fc2)\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcc2d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # define the input shape\n",
    "# input_shape = (6, 14)\n",
    "\n",
    "# # create the input placeholder for the model\n",
    "# input_data = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# # reshape input data\n",
    "# input_data_reshaped = tf.keras.layers.Reshape((6, 14, 1))(input_data)\n",
    "\n",
    "# # define the convolutional layer\n",
    "# conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_data_reshaped)\n",
    "\n",
    "# # add maxpooling layer\n",
    "# maxpooling = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
    "\n",
    "\n",
    "# reshaped = tf.keras.layers.Reshape((2, 6*32))(maxpooling)\n",
    "\n",
    "# # define the recurrent layer\n",
    "# rnn = tf.keras.layers.GRU(units=64, return_sequences=True)(reshaped)\n",
    "\n",
    "# # add flatten layer\n",
    "# flatten = tf.keras.layers.Flatten()(rnn)\n",
    "\n",
    "# # define the fully connected layers\n",
    "# fc1 = tf.keras.layers.Dense(units=64, activation='relu')(flatten)\n",
    "# fc2 = tf.keras.layers.Dense(units=5, activation='softmax')(fc1)\n",
    "\n",
    "# # define the model\n",
    "# model = tf.keras.Model(inputs=input_data, outputs=fc2)\n",
    "\n",
    "# # compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f075d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bed79725-2bb3-47ce-b06c-333c662b30bf",
    "outputId": "4354cc75-e44d-4d2a-ac4b-c55a4b3a9305"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'categorical_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'categorical_accuracy'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "3b65d81f-3d75-43d1-9e2d-88cef69d110b",
    "outputId": "97e18fb9-4340-478c-e307-82c03282e9cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][10:])\n",
    "plt.plot(history.history['val_loss'][10:])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a964a60-488a-431e-8bcc-586e90d8956b",
   "metadata": {
    "id": "8a964a60-488a-431e-8bcc-586e90d8956b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = CNN.predict(X_test)\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7C0QyTLHO8q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7C0QyTLHO8q",
    "outputId": "78587010-2aa8-4cc7-e82f-7c40e11ce705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2129553e-19, 2.8098260e-31, 9.2449215e-13, 1.0000000e+00,\n",
       "        9.4754170e-12],\n",
       "       [2.8277391e-12, 5.0063885e-20, 9.9999952e-01, 4.2008796e-07,\n",
       "        3.0396743e-24],\n",
       "       [9.9999988e-01, 9.1710753e-08, 6.3469877e-15, 1.1851743e-10,\n",
       "        5.9902339e-15],\n",
       "       ...,\n",
       "       [9.9997890e-01, 2.0939477e-05, 2.2540238e-12, 1.5323592e-07,\n",
       "        3.6309597e-08],\n",
       "       [1.5036849e-11, 6.1162949e-19, 9.9999964e-01, 3.7966666e-07,\n",
       "        4.2271948e-24],\n",
       "       [2.2021037e-02, 9.7797799e-01, 1.0109043e-06, 1.3656522e-08,\n",
       "        3.6313619e-12]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ljWvGo9skgS",
   "metadata": {
    "id": "1ljWvGo9skgS"
   },
   "outputs": [],
   "source": [
    "y_pred= np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "BIninuG_Hixu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIninuG_Hixu",
    "outputId": "8d52a3ce-46d5-41c3-f339-ec8e2feee684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, ..., 0, 2, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3NzoyhrD4tO9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NzoyhrD4tO9",
    "outputId": "da09ab77-c439-431e-82a8-93fc98f20b49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57",
   "metadata": {
    "id": "48c3e9c7-2bc3-479a-8af1-bf35d87f3e57"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'y_test': y_test.ravel().astype(int).tolist(),\n",
    "    'y_pred': y_pred.ravel().astype(int).tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "18cfafbe-dafb-4a9e-8873-7f96e71f80b8",
    "outputId": "aa49cb9d-c88e-437b-9a31-2809577d1da1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2374</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred     0     1     2     3     4\n",
       "y_test                              \n",
       "0       7117     0     0    23    57\n",
       "1         20  2374     3     0     0\n",
       "2          0     0  2397     0     0\n",
       "3          0     0     0  2397     0\n",
       "4          0     0     0     0  2397"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df['y_test'], df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f",
   "metadata": {
    "id": "e192957b-1b16-47c8-89eb-d6e2fb9bde9f"
   },
   "outputs": [],
   "source": [
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZD1w6TZwk0e",
   "metadata": {
    "id": "vZD1w6TZwk0e"
   },
   "outputs": [],
   "source": [
    "CNN.save('model_21_01_2023_com_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413c816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f112bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
